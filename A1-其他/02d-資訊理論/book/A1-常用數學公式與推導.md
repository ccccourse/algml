### A1 - 常用數學公式與推導

在信息理論中，許多數學公式與推導是理解各種概念的基礎，以下列出了一些常用的公式及其推導。

#### **1. 熵（Entropy）**

熵是信息理論中衡量隨機變量不確定性的基本量度。對於一個離散隨機變量 \( X \) ，其熵定義為：

\[
H(X) = - \sum_{i} P(x_i) \log_2 P(x_i)
\]

其中，\( P(x_i) \) 是隨機變量 \( X \) 取值 \( x_i \) 的概率，\( \log_2 \) 是對數底為 2。

- **推導：**
  熵的推導基於信息量的定義，即當我們得到一個事件 \( x_i \) 發生時，它所帶來的信息量為 \( -\log_2 P(x_i) \)。熵是這些信息量的期望值。

#### **2. 互信息（Mutual Information）**

互信息量度了兩個隨機變量之間的依賴關係。對於隨機變量 \( X \) 和 \( Y \)，其互信息 \( I(X;Y) \) 定義為：

\[
I(X; Y) = H(X) + H(Y) - H(X, Y)
\]

或者也可以寫作：

\[
I(X; Y) = \sum_{x_i \in X} \sum_{y_j \in Y} P(x_i, y_j) \log_2 \frac{P(x_i, y_j)}{P(x_i) P(y_j)}
\]

其中 \( P(x_i, y_j) \) 是 \( X \) 和 \( Y \) 的聯合概率分佈，\( P(x_i) \) 和 \( P(y_j) \) 分別是 \( X \) 和 \( Y \) 的邊際分佈。

- **推導：**
  互信息可以看作是隨機變量 \( X \) 和 \( Y \) 共同帶來的“信息”。其實質是衡量知道一個變量後，對另一個變量不確定性的減少程度。

#### **3. 交叉熵（Cross-Entropy）**

交叉熵測量了兩個概率分佈之間的差異，常用於機器學習中的損失函數。對於實際分佈 \( P \) 和預測分佈 \( Q \)，交叉熵定義為：

\[
H(P, Q) = - \sum_{i} P(x_i) \log_2 Q(x_i)
\]

- **推導：**
  交叉熵可以看作是將真實分佈 \( P \) 用預測分佈 \( Q \) 進行編碼所需的額外“信息量”。它是衡量兩個分佈之間的差異的指標，並且在深度學習中被用作計算損失的工具。

#### **4. 相對熵（Kullback-Leibler Divergence）**

相對熵（也稱為KL散度）衡量兩個概率分佈之間的差異。對於兩個概率分佈 \( P \) 和 \( Q \)，其KL散度定義為：

\[
D_{KL}(P || Q) = \sum_{i} P(x_i) \log_2 \frac{P(x_i)}{Q(x_i)}
\]

- **推導：**
  KL散度是交叉熵與熵之間的差異，即：

  \[
  D_{KL}(P || Q) = H(P, Q) - H(P)
  \]

  它是一個非對稱量度，描述了將 \( P \) 進行 \( Q \)-分佈編碼所需的額外信息量。

#### **5. 信道容量（Channel Capacity）**

信道容量是通信系統能夠以最大信息傳遞速度穩定傳輸信息的上限。對於一個信道 \( W \)，其信道容量 \( C \) 定義為：

\[
C = \max_{P_X} I(X; Y)
\]

其中，\( I(X; Y) \) 是輸入 \( X \) 和輸出 \( Y \) 之間的互信息，最大化互信息是通過選擇最佳的輸入概率分佈 \( P_X \) 來達成。

- **推導：**
  信道容量的計算基於最大化輸入和輸出之間的互信息，並且在香農的信道容量定理中，這一概念是用來確定有無失真的情況下可達到的最高數據傳輸速率。

#### **6. 霍夫曼編碼（Huffman Coding）**

霍夫曼編碼是一種最優的無損數據壓縮算法，它基於字元的出現頻率構建最優編碼樹。假設一組字元的頻率為 \( \{P_1, P_2, ..., P_n\} \)，霍夫曼編碼的基本步驟如下：

1. 根據頻率對字元進行排序。
2. 選擇兩個最小頻率的字元，將其合併為一個新的節點。
3. 重複這一過程，直到所有字元都合併成一棵樹。

- **推導：**
  霍夫曼編碼利用頻率較高的字元分配較短的編碼，頻率較低的字元分配較長的編碼，從而最小化總編碼長度。

#### **7. 算術編碼（Arithmetic Coding）**

算術編碼是一種基於區間縮放的無損壓縮方法，它根據字元的概率分佈動態地分配編碼。

1. 將整個消息視為一個區間，並根據每個字元的概率分佈來縮小區間。
2. 根據字元的順序繼續縮小區間，最終得到對應的編碼。

- **推導：**
  算術編碼將每個字元的區間映射到實數範圍，並將整個消息編碼為這個區間內的一個實數。

#### **8. 基本的線性編碼公式**

對於一個線性編碼，對應的碼字可以用一個生成矩陣 \( G \) 和信息向量 \( \mathbf{u} \) 表示：

\[
\mathbf{c} = \mathbf{u} G
\]

其中，\( \mathbf{c} \) 是碼字，\( \mathbf{u} \) 是信息向量，\( G \) 是生成矩陣。這個公式是描述線性編碼的基本方法，並可以用於理解錯誤檢測和糾正的編碼設計。

---

以上是信息理論中一些常見的數學公式與推導。這些公式構成了信息理論的核心基礎，並在通信、數據壓縮、機器學習等領域有著廣泛的應用。