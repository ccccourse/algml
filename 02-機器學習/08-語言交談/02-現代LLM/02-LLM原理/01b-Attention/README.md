# Attention

* [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
* [Attention Heads of Large Language Models: A Survey](https://arxiv.org/abs/2409.03752)

