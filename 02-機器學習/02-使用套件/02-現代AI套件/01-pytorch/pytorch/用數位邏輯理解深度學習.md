## 用數位邏輯理解深度學習

1. 非循環神經網路： 組合邏輯 f(x)
2. 循環神經網路： 循序邏輯 s[t+1] = f(x, s[t])

為何加上非線性層，像是 Sigmoid 或 ReLU

否則就會退化成矩陣相乘，那能力就是線性的，只要用一個矩陣就能表示了。

1. sigmoid(w1 x + w2 y - b) 或 ReLU(w1 x + w2 y - b) 可以模仿 and, or 。
2. 所以多層的上述元件就可以做出 xor  (ab' + a'b)。
3. 因此任何邏輯電路都可以用多層神經網路兜出來。



