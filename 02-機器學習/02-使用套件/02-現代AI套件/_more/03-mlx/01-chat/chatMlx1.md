
```
 cccimac@cccimacdeiMac 01-chat % python chatMlx1.py
special_tokens_map.json: 100%|██████████████████████| 296/296 [00:00<00:00, 1.25MB/s]
model.safetensors.index.json: 100%|██████████████| 26.2k/26.2k [00:00<00:00, 810kB/s]
tokenizer_config.json: 100%|█████████████████████| 54.5k/54.5k [00:00<00:00, 341kB/s]
config.json: 100%|██████████████████████████████| 1.12k/1.12k [00:00<00:00, 4.85MB/s]
tokenizer.json: 100%|███████████████████████████| 9.09M/9.09M [00:07<00:00, 1.18MB/s]
model.safetensors: 100%|██████████████████████████| 695M/695M [04:42<00:00, 2.46MB/s]
Fetching 6 files: 100%|████████████████████████████████| 6/6 [04:43<00:00, 47.28s/it]
==========tensors: 100%|██████████████████████████| 695M/695M [04:42<00:00, 2.49MB/s]
Prompt: 什麼是 Llama AI 模型？
 Llama 是 Amazon 的基於自然語言處理的語言模型，適合用於文本生成和解析。它是由 Meta 的 BigBird 和 XLSys 的 GPT-3.2L 來源模型合成而成的。 Llama 模型通過使用基於自然語言處理的基礎，來處理和生成文本。它可以在文本中找到模式，生成相應的文本。
==========
Prompt: 11 tokens, 27.744 tokens-per-sec
Generation: 100 tokens, 103.035 tokens-per-sec
Peak memory: 0.659 GB
```
