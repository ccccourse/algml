### 感知器理論

**感知器**（Perceptron）是最早提出的一種神經網路模型，由弗蘭克·羅森布拉特（Frank Rosenblatt）於1958年開發。它是一種線性分類器，能夠將輸入樣本劃分為兩個類別。感知器是單層神經網路的基本結構，能夠處理線性可分的數據集。

#### 1. 感知器的基本結構

感知器由以下幾部分組成：
- **輸入層**：接收輸入特徵向量 \( \mathbf{x} = [x_1, x_2, \dots, x_n] \)。
- **權重向量**：每個輸入都有對應的權重 \( \mathbf{w} = [w_1, w_2, \dots, w_n] \)。
- **加權求和**：計算輸入向量與權重向量的內積 \( z = \mathbf{w} \cdot \mathbf{x} + b \)，其中 \( b \) 是偏置項。
- **激活函數**：使用階躍函數 \( f(z) \) 來決定輸出類別。若 \( z \geq 0 \)，則輸出1；否則輸出0。

#### 2. 感知器學習算法

感知器使用一種基於梯度下降的學習算法來更新權重，使其能夠正確分類輸入樣本。學習過程如下：
1. 初始化權重向量和偏置項。
2. 對於每個訓練樣本 \( (\mathbf{x}_i, y_i) \)，計算預測輸出 \( \hat{y}_i \)。
3. 如果 \( \hat{y}_i \neq y_i \)，則更新權重和偏置：
   \[
   \mathbf{w} = \mathbf{w} + \eta (y_i - \hat{y}_i) \mathbf{x}_i
   \]
   \[
   b = b + \eta (y_i - \hat{y}_i)
   \]
   其中 \( \eta \) 是學習率。

4. 重複步驟2和3，直到模型在所有樣本上的預測正確或達到最大迭代次數。

#### 3. 感知器的數學描述

給定一組輸入特徵 \( \mathbf{x} \) 和對應的標籤 \( y \in \{0, 1\} \)，感知器的輸出為：
\[
\hat{y} = 
\begin{cases} 
1, & \text{if } \mathbf{w} \cdot \mathbf{x} + b \geq 0 \\
0, & \text{otherwise}
\end{cases}
\]
其中，權重向量 \( \mathbf{w} \) 和偏置項 \( b \) 是通過學習過程來更新的。

#### 4. 感知器的優缺點

**優點**：
- **簡單易理解**：感知器模型的結構和學習算法非常簡單，易於理解和實現。
- **快速訓練**：由於其簡單的結構，感知器的訓練速度非常快。

**缺點**：
- **僅能處理線性可分的問題**：感知器無法處理非線性可分的數據集。例如，XOR問題無法通過感知器來解決。
- **對噪聲敏感**：感知器對於有噪聲的數據表現較差，因為它使用階躍函數作為激活函數。

#### 5. Python實現（基於`numpy`的感知器）

以下是一個簡單的感知器模型實現，適用於二分類任務：

```python
import numpy as np

class Perceptron:
    def __init__(self, learning_rate=0.01, n_iter=1000):
        self.learning_rate = learning_rate
        self.n_iter = n_iter
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.weights = np.zeros(n_features)
        self.bias = 0

        for _ in range(self.n_iter):
            for idx, x_i in enumerate(X):
                linear_output = np.dot(x_i, self.weights) + self.bias
                y_predicted = self._activation_function(linear_output)

                update = self.learning_rate * (y[idx] - y_predicted)
                self.weights += update * x_i
                self.bias += update

    def predict(self, X):
        linear_output = np.dot(X, self.weights) + self.bias
        y_predicted = self._activation_function(linear_output)
        return y_predicted

    def _activation_function(self, x):
        return np.where(x >= 0, 1, 0)

# 使用示例
if __name__ == "__main__":
    # 示例數據
    X = np.array([[1, 1], [2, 1], [1, 2], [2, 2], [3, 3]])
    y = np.array([0, 0, 1, 1, 1])

    # 訓練感知器
    perceptron = Perceptron(learning_rate=0.1, n_iter=10)
    perceptron.fit(X, y)

    # 預測
    predictions = perceptron.predict(X)
    print(f"預測結果: {predictions}")
```

#### 6. 程式解釋

- **`fit` 方法**：用於訓練感知器，更新權重和偏置以最小化預測誤差。
- **`predict` 方法**：使用訓練好的感知器進行預測，返回預測類別。
- **`_activation_function` 方法**：實現階躍函數，決定輸出類別。

這個簡單的感知器實現展示了如何使用基於梯度下降的學習算法來訓練模型，並進行二分類任務。