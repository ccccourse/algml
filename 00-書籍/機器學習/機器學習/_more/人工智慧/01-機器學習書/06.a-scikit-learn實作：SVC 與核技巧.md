### **scikit-learn 實作：SVC 與核技巧**

在 scikit-learn 中，支持向量機的實現是通過 `SVC`（支持向量分類器）來完成的。`SVC` 支援多種核函數，包括線性核、多項式核、RBF 核和 Sigmoid 核等，可以處理線性和非線性分類問題。

#### **1. 基本概念：SVC 的使用**

`SVC` 類是 scikit-learn 中實現 SVM 的主要工具。它提供了對各種核函數的支持，並且能夠處理二分類和多分類問題。使用 `SVC` 時，我們可以選擇不同的核函數來解決線性或非線性可分的分類問題。

SVC 的主要參數包括：
- `C`：正則化參數，控制分類器對錯誤分類的懲罰。較大的 `C` 值會使模型對錯誤分類的懲罰加重，從而導致過擬合。
- `kernel`：選擇核函數的類型，包括 `'linear'`（線性核）、`'poly'`（多項式核）、`'rbf'`（徑向基核）和 `'sigmoid'`（Sigmoid 核）。
- `gamma`：核函數的參數。對於 RBF 和多項式核，`gamma` 控制樣本點對分類邊界的影響範圍。較小的 `gamma` 值會使邊界更平滑，較大的 `gamma` 值則會使邊界更複雜。

#### **2. scikit-learn 實作範例**

以下是使用 `SVC` 來實現不同核技巧的分類任務的範例。這些範例展示了如何使用 `SVC` 進行線性和非線性分類。

##### **線性核（Linear Kernel）**

線性核適用於數據線性可分的情況。這裡，我們使用 scikit-learn 的 `make_classification` 生成一些線性可分的數據，並使用線性核來訓練 SVM 模型。

```python
import numpy as np
from sklearn.svm import SVC
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 生成線性可分的數據
X, y = make_classification(n_samples=100, n_features=2, n_classes=2, random_state=42)

# 切分數據集為訓練集和測試集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 使用線性核的 SVC 模型
model = SVC(kernel='linear')
model.fit(X_train, y_train)

# 預測並評估模型
y_pred = model.predict(X_test)
print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')
```

在這個範例中，我們使用了線性核來訓練 SVM 模型。由於數據是線性可分的，這樣的模型能夠得到較高的分類準確度。

##### **RBF 核（Radial Basis Function Kernel）**

對於非線性可分的數據，RBF 核是一個常用的選擇。這裡，我們使用 `make_classification` 生成一些非線性可分的數據，並使用 RBF 核來訓練 SVM 模型。

```python
from sklearn.datasets import make_circles

# 生成非線性可分的數據（圓形分佈）
X, y = make_circles(n_samples=100, noise=0.1, factor=0.4, random_state=42)

# 切分數據集為訓練集和測試集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 使用 RBF 核的 SVC 模型
model = SVC(kernel='rbf', gamma='scale')  # 'scale' 是 gamma 的一個選項
model.fit(X_train, y_train)

# 預測並評估模型
y_pred = model.predict(X_test)
print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')
```

這個範例使用了 `make_circles` 生成非線性可分的數據（即兩個圓形的分佈），並使用 RBF 核來解決這個問題。由於 RBF 核能夠有效地將數據映射到高維空間，並處理非線性分離問題，因此模型能夠成功分類這些非線性可分的數據。

##### **多項式核（Polynomial Kernel）**

多項式核通常用於當數據的分佈可以通過多項式函數來表示時。以下是使用多項式核的範例：

```python
# 使用多項式核的 SVC 模型
model = SVC(kernel='poly', degree=3, gamma='scale')
model.fit(X_train, y_train)

# 預測並評估模型
y_pred = model.predict(X_test)
print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')
```

在這個範例中，我們使用了三次多項式核（`degree=3`）來進行分類。`degree` 參數控制多項式的次數，而 `gamma` 則控制樣本對邊界的影響範圍。

---

#### **3. 小結**

- **SVC** 是 scikit-learn 中實現支持向量機分類的工具，支持多種核函數，包括線性核、多項式核、RBF 核和 Sigmoid 核。
- 核技巧能夠將數據映射到更高維的特徵空間，使得原本非線性可分的數據變得線性可分。
- 在選擇合適的核函數時，需要根據數據的特徵來決定。線性核適用於線性可分的數據，而 RBF 核和多項式核適用於非線性可分的數據。
- 調整 SVC 模型的超參數（如 `C`、`gamma`、`kernel`）對模型的性能有很大的影響，通常需要通過交叉驗證來選擇最佳參數。