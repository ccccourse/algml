

# 機器學習

### 第一部分：機器學習的數學基石  
1. **機器學習的數學視角**  
   - 機器學習的數學框架  
   - scikit-learn 的架構與數學依據  
2. **線性代數與矩陣運算**  
   - 向量空間與線性映射  
   - 矩陣分解（LU 分解、QR 分解、SVD）  
   - scikit-learn 與矩陣運算的結合  
3. **機率與統計基礎**  
   - 隨機變數與概率分佈  
   - 條件概率與貝葉斯推論  
   - 最大似然估計（MLE）與最大後驗估計（MAP）  
4. **優化理論與算法**  
   - 凸優化：Lagrange 乘數法與 KKT 條件  
   - 梯度方法：SGD 與二階優化算法  
   - scikit-learn 中的優化實現  

---

### 第二部分：監督式學習的數學與實踐  
5. **回歸模型的數學解析**  
   - 線性回歸與廣義線性模型  
   - 正則化方法：Lasso 與 Ridge  
   - scikit-learn 的實現：Pipeline 與 LinearRegression  
6. **分類模型的數學框架**  
   - Logistic 回歸的損失函數與梯度推導  
   - 支持向量機（SVM）的核函數理論  
   - scikit-learn 實作：SVC 與核技巧  
7. **決策樹與 Boosting 方法**  
   - 信息熵與信息增益  
   - AdaBoost 與梯度提升算法（GBDT）  
   - scikit-learn 實作：GradientBoostingClassifier 與 XGBoost 接口  

---

### 第三部分：非監督式學習的數學與應用  
8. **聚類算法的數學原理**  
   - K-means 的收斂性與空間劃分  
   - DBSCAN 的密度估計方法  
   - scikit-learn 的實現：KMeans 與 SpectralClustering  
9. **降維方法的數學框架**  
   - PCA：協方差矩陣與特徵分解  
   - 非線性降維：t-SNE 與 UMAP 的數學模型  
   - scikit-learn 的實現與優化  
10. **生成模型與概率分佈**  
    - 高斯混合模型（GMM）與期望最大化算法（EM）  
    - 隱馬爾科夫模型（HMM）的數學推導  
    - scikit-learn 實作：GaussianMixture 與 HMM  

---

### 第四部分：模型評估與選擇  
11. **數據集劃分與交叉驗證**  
    - 偏差-方差分解與泛化能力分析  
    - 留一法、K 折交叉驗證與 scikit-learn 的實現  
12. **評估指標與 ROC 曲線解析**  
    - 混淆矩陣與 AUC 的數學定義  
    - 多類分類的評估指標  
    - scikit-learn 的性能度量工具  
13. **超參數調優的數學理論**  
    - 貝葉斯優化的理論框架  
    - 隨機搜索與網格搜索的比較  
    - scikit-learn 的 Hyperparameter Tuning 工具  

---

### 第五部分：進階與應用  
14. **多目標學習與 Ensemble 方法**  
    - Bagging、Boosting 與 Stacking 的理論與實踐  
    - scikit-learn 的 VotingClassifier 與 StackingClassifier  
15. **時間序列分析與預測**  
    - 自回歸模型（AR）與移動平均模型（MA）  
    - 特徵工程與時序分解  
    - scikit-learn 與 statsmodels 的集成應用  
16. **神經網路的數學視角**  
    - 感知機到 MLP 的數學推導  
    - scikit-learn 與神經網絡的接口  

---

### 第六部分：應用實例與實踐  
17. **完整機器學習工作流程**  
    - 數據處理、建模與部署的整合案例  
    - scikit-learn 與 MLflow 的結合  
18. **特定領域的應用案例**  
    - 金融風險分析的數學模型  
    - 醫療數據的機器學習分析  


