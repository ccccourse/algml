### **貝葉斯優化的理論框架**

貝葉斯優化（Bayesian Optimization, BO）是一種用於黑盒函數優化的方法，尤其適用於需要昂貴計算或評估的優化問題，如超參數調優、物理實驗設計等。其基本思想是將優化過程建模為一個貝葉斯推理問題，通過不斷更新模型來引導搜尋過程，以期能在有限的計算次數內找到最優解。

#### **1. 貝葉斯優化的基本原理**

貝葉斯優化主要基於貝葉斯推理，它假設我們的目標函數（即待優化的黑盒函數）是由一個隱藏的概率分佈生成的，並通過觀察該函數的樣本來更新對該函數的信念。這樣的過程可以用來在不直接計算目標函數的情況下，推斷出在某些點進行評估最有可能獲得最佳結果。

貝葉斯優化的基本框架包括三個重要的組成部分：

1. **目標函數**：假設需要優化的目標函數 \( f(x) \) 是黑盒的，即我們無法直接解析出其表達式，只能通過試驗不同的輸入 \( x \) 並觀察對應的輸出 \( y = f(x) \) 來了解函數的性質。
   
2. **先驗分佈**：為了進行貝葉斯推理，我們首先對目標函數的潛在形式設置一個先驗分佈。通常，這個先驗會假設目標函數是某種類型的平滑函數。例如，最常用的是高斯過程（Gaussian Process, GP）。

3. **後驗更新與選擇最佳點**：每當我們觀察到一個新的數據點（即 \( x_n \) 和 \( y_n = f(x_n) \)）時，我們會基於已經觀察到的數據更新對目標函數的後驗分佈，並根據這個後驗分佈來選擇下一個最有可能最優的樣本點。

#### **2. 高斯過程（Gaussian Process）**

高斯過程是貝葉斯優化中常用的先驗模型，它被用來描述目標函數的分佈。高斯過程是一種非參數化的模型，它假設函數的每個值都是從一個高斯分佈中抽樣出來的，並且這些值之間有某種內在的相關性，這種相關性由一個核函數（kernel function）來描述。

高斯過程的核心數學模型為：

\[
f(x) \sim \mathcal{GP}(\mu(x), k(x, x'))
\]

其中，\( \mu(x) \) 是均值函數，描述了目標函數的平均行為；\( k(x, x') \) 是核函數，表示不同點之間的相關性。

高斯過程通過這些核函數來預測目標函數在未觀察點的行為，並給出該點的均值預測和不確定性（即方差），這對於貝葉斯優化至關重要，因為它幫助決策過程在高不確定性的地方進行探索。

#### **3. 探索與利用的權衡**

在貝葉斯優化過程中，選擇下一個要評估的點是關鍵。這一選擇通常依賴於探索（exploration）與利用（exploitation）之間的權衡：

- **利用（Exploitation）**：基於當前的後驗分佈，選擇最有可能帶來最優解的點。這樣的策略傾向於選擇已經證明具有較好性能的區域。
  
- **探索（Exploration）**：選擇那些不確定性較高的區域，這有助於發現潛在的、更好的解。

這種探索與利用的平衡通常通過**獲取函數（Acquisition Function）**來實現。獲取函數衡量了不同選擇點的價值，並指導貝葉斯優化的搜尋過程。

#### **4. 獲取函數（Acquisition Function）**

獲取函數是一個決策過程中使用的指標，用來量化在某個位置進行評估的"價值"。它通常基於高斯過程的預測來計算，並且其目的是在探索和利用之間取得平衡。常見的獲取函數有：

- **預測均值（Expected Improvement, EI）**：計算在某個點上的改進的期望值，即新點比當前最佳點的預期改進。

\[
EI(x) = \mathbb{E}[\max(0, f^* - f(x))]
\]

其中 \( f^* \) 是當前已知的最佳函數值。

- **概率改進（Probability of Improvement, PI）**：計算新點比當前最佳點更好的概率。

\[
PI(x) = \mathbb{P}[f(x) \geq f^* + \xi]
\]

- **上置信界（Upper Confidence Bound, UCB）**：根據高斯過程的均值和方差來選擇點，對於每個點，計算其預測均值加上某種方差的加權。

\[
UCB(x) = \mu(x) + \kappa \sigma(x)
\]

其中，\( \mu(x) \) 和 \( \sigma(x) \) 分別是高斯過程在點 \( x \) 上的預測均值和標準差，\( \kappa \) 是調節探索與利用的超參數。

#### **5. 優化過程**

貝葉斯優化的過程如下：

1. **初始化**：選擇一組初始點並計算目標函數的值。
2. **擬合高斯過程模型**：根據已知的數據點擬合高斯過程模型，計算其均值和方差。
3. **選擇下一個樣本點**：使用獲取函數選擇下一個樣本點。
4. **評估目標函數**：在選擇的點上評估目標函數並更新數據。
5. **更新高斯過程模型**：根據新的數據點更新高斯過程模型。
6. 重複步驟 3-5 直到達到停止條件（例如，達到最大評估次數或收斂）。

#### **6. 貝葉斯優化的優勢與挑戰**

**優勢：**
- 能夠有效地處理高維、昂貴計算的目標函數。
- 具有較少的計算次數即可找到接近最優的解。
- 可應用於各種黑盒優化問題，如超參數調優。

**挑戰：**
- 需要合理選擇核函數，否則高斯過程可能無法很好地擬合目標函數。
- 計算複雜度較高，尤其是在高維空間中。
- 優化過程可能會受到先驗選擇的影響，並且在某些情況下可能會過度依賴於現有數據的局部性。

總結來說，貝葉斯優化是一個非常強大的工具，特別適用於超參數調優等需要有限次計算的情境。它通過貝葉斯推理模型和獲取函數來平衡探索與利用，從而在較少的計算資源下達到較好的優化效果。