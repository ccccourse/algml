### **支持向量機（SVM）的核函數理論**

支持向量機（SVM）是一種強大的分類和回歸方法，特別適用於高維度的數據集。SVM 的基本思想是通過尋找一個最優的超平面來將不同類別的樣本分開。當數據是線性可分時，這個問題是直接的，SVM 的目標是最大化兩類之間的間隔（即超平面的邊界）。然而，在許多現實情況中，數據可能是非線性可分的，這時候 SVM 通過引入 **核函數** 來解決這個問題。

#### **1. 基本的 SVM 概念**
對於二分類問題，SVM 的目標是找到一個超平面 \( h(\mathbf{x}) = w^T \mathbf{x} + b = 0 \)，使得樣本點被正確分離，且該超平面到最接近的樣本點的距離（稱為間隔）最大化。最優的超平面是能夠最大化邊界的平面，這也就是 SVM 中的 **最大間隔分類器**。

假設我們有一組線性可分的數據集：

\[
\mathbf{x}_i \in \mathbb{R}^n, \quad y_i \in \{+1, -1\}, \quad i = 1, 2, \dots, m
\]

我們的目標是找出一個超平面來分類這些樣本點。SVM 的數學問題可以表述為：

\[
\text{maximize} \quad \frac{1}{\|w\|}
\]
subject to:
\[
y_i (w^T \mathbf{x}_i + b) \geq 1 \quad \text{for all} \quad i
\]

這是通過最大化邊界（即 \( \frac{1}{\|w\|} \)）來分離兩類樣本的目標。

---

#### **2. 核方法的引入**
當數據不是線性可分時，SVM 需要透過引入一個 **核函數**，將數據從原始空間映射到一個高維空間，使得在這個高維空間中，數據變得線性可分。核函數的基本思想是，將原始數據點通過一個映射函數 \( \phi(\mathbf{x}) \) 映射到一個高維的特徵空間，這樣就能找到一個線性可分的超平面。

最重要的是，通過使用核技巧，我們不需要顯式地計算映射 \( \phi(\mathbf{x}) \)，而是利用 **核函數** \( K(\mathbf{x}_i, \mathbf{x}_j) = \langle \phi(\mathbf{x}_i), \phi(\mathbf{x}_j) \rangle \)，直接計算高維空間中的內積。

#### **3. 常見的核函數**
有幾種常見的核函數，這些函數能夠將數據映射到不同的高維空間：

- **線性核**：
  \[
  K(\mathbf{x}_i, \mathbf{x}_j) = \mathbf{x}_i^T \mathbf{x}_j
  \]
  這對應於原始空間中的線性分離，適用於線性可分的情況。

- **多項式核**：
  \[
  K(\mathbf{x}_i, \mathbf{x}_j) = (\mathbf{x}_i^T \mathbf{x}_j + c)^d
  \]
  這對應於將數據映射到多項式特徵空間，能夠處理一些非線性分離的情況。

- **高斯徑向基核（RBF 核）**：
  \[
  K(\mathbf{x}_i, \mathbf{x}_j) = \exp\left(-\frac{\|\mathbf{x}_i - \mathbf{x}_j\|^2}{2\sigma^2}\right)
  \]
  RBF 核是最常用的非線性核函數，能夠將數據映射到一個無窮維的特徵空間，使得它能夠處理複雜的非線性分類問題。

- **Sigmoid 核**：
  \[
  K(\mathbf{x}_i, \mathbf{x}_j) = \tanh(\alpha \mathbf{x}_i^T \mathbf{x}_j + c)
  \]
  這是基於神經網絡的激活函數（Sigmoid）的核函數，用於非線性映射。

---

#### **4. SVM 的優化問題**
在使用核函數後，SVM 的最優化問題變為：

\[
\text{maximize} \quad \frac{1}{\|w\|} = \frac{1}{\sqrt{\sum_{i,j} \alpha_i \alpha_j y_i y_j K(\mathbf{x}_i, \mathbf{x}_j)}}
\]

這裡的 \( \alpha_i \) 是拉格朗日乘子，\( K(\mathbf{x}_i, \mathbf{x}_j) \) 是核函數，並且這個最優化問題可以通過 **拉格朗日對偶性** 進行求解。

通過解這個最優化問題，SVM 可以得到最佳的分類超平面，並且在高維空間中進行非線性分類。

---

#### **5. 小結**
- **核方法** 是 SVM 中用來處理非線性可分問題的核心技術，它通過將數據映射到高維空間，使得原本非線性可分的數據變得線性可分。
- 常見的核函數包括線性核、多項式核、高斯 RBF 核和 Sigmoid 核等，它們能夠應對不同類型的非線性問題。
- 通過核技巧，SVM 不僅可以在高維空間中進行優化，還避免了顯式地計算高維映射，這使得 SVM 成為一個高效且強大的分類算法。

在實際應用中，選擇合適的核函數和正則化參數對於 SVM 的性能至關重要。