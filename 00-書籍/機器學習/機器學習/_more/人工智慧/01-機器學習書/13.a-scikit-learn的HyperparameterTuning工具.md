### **scikit-learn 的 Hyperparameter Tuning 工具**

在機器學習中，超參數調優（Hyperparameter Tuning）是模型訓練過程中的一個重要步驟，目的是選擇最合適的超參數組合來提高模型的性能。`scikit-learn` 提供了多種工具來幫助進行超參數調優，主要包括 **GridSearchCV**、**RandomizedSearchCV** 和 **HalvingGridSearchCV**，這些工具支持自動化超參數搜索並可輕鬆與交叉驗證結合。

以下是對這些工具的詳細介紹和使用範例。

#### **1. GridSearchCV**

`GridSearchCV` 是 `scikit-learn` 提供的最常用的超參數調優工具之一。它通過在給定的超參數範圍內進行網格搜索，來找到最佳的超參數組合。每次選擇一組超參數，並對其進行交叉驗證，最終返回最優的超參數。

**特點**：
- 系統地遍歷所有的超參數組合。
- 使用交叉驗證來選擇最優的超參數配置。

**使用方法**：
```python
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# 定義模型和超參數範圍
model = RandomForestClassifier()
param_grid = {
    'n_estimators': [10, 50, 100],
    'max_depth': [5, 10, 20]
}

# 使用 GridSearchCV 進行超參數調優
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)

# 輸出最佳參數和對應的分數
print("最佳參數：", grid_search.best_params_)
print("最佳得分：", grid_search.best_score_)
```

#### **2. RandomizedSearchCV**

`RandomizedSearchCV` 通過隨機選擇超參數組合來進行調優，這樣能夠避免網格搜索在較大範圍內的計算開銷。相較於網格搜索，隨機搜索更加高效，特別是在超參數空間很大時。

**特點**：
- 在給定的範圍內隨機選擇超參數組合，避免了完整遍歷的高計算開銷。
- 可以設置迭代次數來限制搜索的範圍。

**使用方法**：
```python
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from scipy.stats import randint

# 定義模型和超參數範圍
model = RandomForestClassifier()
param_dist = {
    'n_estimators': randint(10, 200),
    'max_depth': randint(5, 20)
}

# 使用 RandomizedSearchCV 進行隨機超參數調優
random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=100, cv=5)
random_search.fit(X_train, y_train)

# 輸出最佳參數和對應的分數
print("最佳參數：", random_search.best_params_)
print("最佳得分：", random_search.best_score_)
```

#### **3. HalvingGridSearchCV**

`HalvingGridSearchCV` 是 `scikit-learn` 提供的一種更加高效的網格搜索方法，它通過逐步減少超參數組合的數量來加速搜索過程。這樣能夠快速過濾掉性能較差的參數配置，將更多計算資源集中在最有可能找到最優解的組合上。

**特點**：
- 逐步淘汰性能不佳的超參數組合，提升搜索效率。
- 特別適合於大規模超參數空間，並且能夠更好地利用計算資源。

**使用方法**：
```python
from sklearn.model_selection import HalvingGridSearchCV
from sklearn.ensemble import RandomForestClassifier

# 定義模型和超參數範圍
model = RandomForestClassifier()
param_grid = {
    'n_estimators': [10, 50, 100, 200],
    'max_depth': [5, 10, 20]
}

# 使用 HalvingGridSearchCV 進行超參數調優
halving_grid_search = HalvingGridSearchCV(estimator=model, param_grid=param_grid, cv=5)
halving_grid_search.fit(X_train, y_train)

# 輸出最佳參數和對應的分數
print("最佳參數：", halving_grid_search.best_params_)
print("最佳得分：", halving_grid_search.best_score_)
```

#### **4. 使用 `scikit-learn` 的工具進行超參數調優的選擇**

- **GridSearchCV**：當你的超參數空間較小且計算資源充足時，網格搜索是最直接且有效的選擇。
- **RandomizedSearchCV**：當你的超參數空間較大，或是時間資源有限時，隨機搜索是一個更加高效的選擇。
- **HalvingGridSearchCV**：當你處理大範圍的超參數空間時，並且需要加速超參數調優過程，可以考慮使用這種逐步減少搜索範圍的方法。

#### **5. `scikit-learn` 的其他優化工具**

- **預設的參數選擇**：一些模型（如 `RandomForestClassifier`, `SVC` 等）已經內建了自動選擇超參數的功能，例如 `max_features='sqrt'` 或 `kernel='rbf'` 等。
- **交叉驗證**：`scikit-learn` 的 `GridSearchCV`, `RandomizedSearchCV` 和 `HalvingGridSearchCV` 都支持交叉驗證，這樣能夠更可靠地評估模型在不同超參數配置下的性能。
- **集成方法**：在一些模型中，如 `RandomForestClassifier` 和 `GradientBoostingClassifier`，你可以使用不同的集成方法來進行多次訓練，進一步提高預測性能。

總結來說，`scikit-learn` 提供的超參數調優工具使得超參數調整變得更加簡單且高效。根據不同的需求和超參數空間大小，選擇適合的調優方法來提高模型的性能。