### **K-means 的收斂性與空間劃分**

K-means 聚類算法是一種廣泛使用的無監督學習方法，用於將數據集分成 K 個簇（clusters）。其主要思想是通過迭代過程，最小化每個簇內點與該簇質心（centroid）之間的距離。在這個過程中，K-means 根據隨機選擇的初始質心進行迭代更新，直到算法收斂。

以下將詳細介紹 K-means 算法的數學背景，特別是其收斂性和空間劃分。

---

### **1. K-means 算法的步驟**

K-means 聚類算法的核心步驟包括：
1. **初始化**：隨機選擇 K 個質心。
2. **分配步驟**：將每個樣本分配到距離最近的質心所對應的簇。
3. **更新步驟**：重新計算每個簇的質心，這個質心是該簇中所有點的平均值。
4. 重複第 2 步和第 3 步，直到質心不再發生變化，或者達到預設的迭代次數。

---

### **2. 收斂性分析**

K-means 算法的收斂性可以從數學上進行分析。每次迭代中，K-means 算法會選擇新的質心，並且重新劃分點，這樣每次都會減少簇內樣本點與質心的總距離。具體來說，K-means 目標是最小化以下的損失函數（或稱為目標函數）：

\[
J = \sum_{i=1}^{N} \sum_{k=1}^{K} r_{ik} \| x_i - \mu_k \|^2
\]

其中：
- \(N\) 是樣本數，
- \(K\) 是簇的數量，
- \(x_i\) 是第 \(i\) 個樣本，
- \(\mu_k\) 是第 \(k\) 個簇的質心，
- \(r_{ik}\) 是指示變量，當樣本 \(x_i\) 屬於簇 \(k\) 時 \(r_{ik} = 1\)，否則為 0。

**收斂性理由**：
1. 每次迭代，樣本的分配會變得更符合其質心，從而減少每個簇內部的樣本距離。
2. 更新質心的過程將質心向每個簇內的樣本的均值移動，從而減少總體距離。
3. 因為每次迭代都會使目標函數的值減小或保持不變，所以 K-means 算法必定會收斂。

然而，K-means 可能會收斂到局部最小值，而不是全局最小值，這取決於初始質心的選擇。因此，為了提高結果的穩定性，通常會運行多次 K-means 並選擇最佳的結果。

---

### **3. 空間劃分**

K-means 算法將特徵空間劃分為 K 個區域，每個區域對應一個簇。這種劃分的數學本質可以通過以下幾個要點來描述：

1. **Voronoi 圖**：
   每次分配樣本到質心的過程可以視為一種 **Voronoi 劃分**。對於每個質心 \( \mu_k \)，將空間劃分為一個區域，這個區域內的所有點都比其他簇的質心更接近 \( \mu_k \)。因此，K-means 的每次迭代都可以看作是對空間進行 Voronoi 劃分。

2. **簇的邊界**：
   每個簇的邊界是由距離最近的質心的點所形成的。在 2D 空間中，這些邊界通常呈現為多邊形形狀。K-means 算法通過不斷更新質心，逐漸調整這些邊界的位置，直到收斂。

3. **質心的影響**：
   質心在每次迭代中都會移動，並且每次移動都會影響簇的邊界。例如，當一個簇的質心向其他簇的邊界靠近時，該簇可能會擴展其邊界，而其他簇則縮小其邊界。

---

### **4. K-means 空間劃分的例子**

假設有一個二維數據集，K-means 聚類的目標是將數據分成 K = 3 個簇。算法的空間劃分將會像下面這樣進行：

1. **初始階段**：
   - 隨機選擇三個質心，將數據集劃分為三個區域，每個區域對應於一個簇。
   
2. **質心更新**：
   - 每個簇的質心會被更新為該簇內所有點的平均位置，從而調整區域的形狀。
   
3. **迭代過程**：
   - 通過不斷的質心更新和樣本分配，簇的邊界將逐漸穩定，直到收斂。

在這個過程中，質心的更新以及點的重新分配會使每個簇的邊界更加合理和精確。最終，簇的邊界會形成一個 Voronoi 分割，即每個點都被分配到最近的質心所對應的簇。

---

### **5. 小結**

- **收斂性**：K-means 算法必定會收斂，因為每次迭代都會減少目標函數的值。然而，它只能收斂到局部最小值，因此結果會受到初始質心選擇的影響。
- **空間劃分**：K-means 算法通過質心更新，對數據空間進行 Voronoi 分割，將空間劃分為 K 個簇。這樣的劃分不僅依賴於質心的位置，還會影響每個簇的形狀和邊界。

了解這些數學原理有助於理解 K-means 算法的運行機制，並且可以幫助我們在實際應用中更好地調整參數（如 K 值）以獲得最佳的聚類效果。