### 機器學習的數學框架  

#### 1.1 機器學習的問題分類  
機器學習問題可概括為三大類型：  
- **監督式學習（Supervised Learning）**：給定標籤的訓練數據，目標是學習 \( f(x) \approx y \)，包括分類與回歸。  
- **非監督式學習（Unsupervised Learning）**：無標籤數據，目標是發現數據內部結構，例如聚類與降維。  
- **強化學習（Reinforcement Learning）**：通過獎勵信號進行學習，目標是找到最優策略 \( \pi^* \)。  

#### 1.2 機器學習的數學目標  
機器學習可形式化為一個優化問題：  
\[
\hat{\theta} = \arg\min_{\theta} \mathcal{L}(f(x; \theta), y)
\]  
其中：  
- \( \theta \)：模型參數，例如權重和偏置。  
- \( \mathcal{L} \)：損失函數，用於衡量模型預測值 \( f(x; \theta) \) 與真實值 \( y \) 的差異。  
- \( x \)：輸入特徵，\( y \)：標籤（監督學習）。  

#### 1.3 機器學習的基本要素  
1. **數據集 \( D \)**：分為訓練集、驗證集與測試集，\( D = \{(x_i, y_i)\}_{i=1}^N \)。  
2. **模型 \( f(x; \theta) \)**：假設空間 \( \mathcal{H} \) 中的函數，例如線性模型、決策樹或神經網絡。  
3. **損失函數 \( \mathcal{L} \)**：評估模型性能的關鍵，例如均方誤差（MSE）、交叉熵損失。  
4. **優化算法**：用於尋找最優參數 \( \hat{\theta} \) 的方法，例如梯度下降。  
5. **泛化能力**：模型對未知數據的預測能力，由偏差-方差分解理論描述。

#### 1.4 數學中的主要概念  
- **概率與統計**：建模不確定性，例如最大似然估計和貝葉斯推論。  
- **線性代數**：支撐多維特徵空間的運算，例如矩陣分解與主成分分析（PCA）。  
- **凸優化**：損失函數的極值求解，例如梯度下降與拉格朗日方法。  
- **信息理論**：度量不確定性與信息量，例如熵與 KL 散度。  

#### 1.5 機器學習框架的抽象  
機器學習可以描述為一個三元組 \( (\mathcal{X}, \mathcal{H}, \mathcal{L}) \)：  
- **特徵空間 \( \mathcal{X} \)**：輸入特徵的集合。  
- **假設空間 \( \mathcal{H} \)**：模型候選集合，例如線性函數集合或深度神經網絡。  
- **目標函數 \( \mathcal{L} \)**：用於優化的目標，例如最小化損失或最大化似然。  

#### 1.6 用 scikit-learn 表現機器學習框架  
在 scikit-learn 中，以上數學概念通過一套統一的 API 實現：  
- **Estimator**：表示假設空間 \( \mathcal{H} \) 中的模型，例如 `LinearRegression`。  
- **Pipeline**：封裝特徵工程與模型的流程，保持一致性。  
- **GridSearchCV**：用於優化模型參數 \( \theta \)。  
- **Metrics**：提供性能評估的數學指標，例如均方誤差與 AUC。  

這一章節將為後續理論與實踐奠定基礎。