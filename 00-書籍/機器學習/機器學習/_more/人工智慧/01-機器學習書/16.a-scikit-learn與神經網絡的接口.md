### **16.4. scikit-learn 與神經網絡的接口**

在 scikit-learn 中，雖然該庫並未將深度學習模型作為核心功能，但它提供了對於較簡單神經網路模型的支持，主要通過 `MLPClassifier` 和 `MLPRegressor` 這兩個類來實現。這些類是多層感知機（MLP）模型的實現，通常用於分類和回歸問題。

在這一小節中，我們將探討如何在 `scikit-learn` 中使用神經網絡模型，包括如何創建、訓練和評估它們。並且將介紹如何與其他 scikit-learn 模型、工具和接口進行集成，提供完整的實作範例。

---

### **1. MLPClassifier 與 MLPRegressor**

- **MLPClassifier**：用於分類問題的多層感知機模型，支持各種激活函數（如 `relu`, `tanh`, `logistic`）和訓練選項（如 `adam`, `sgd`）。
- **MLPRegressor**：用於回歸問題的多層感知機模型，具有與 `MLPClassifier` 類似的功能，但適用於連續值的預測。

#### **(1) 基本範例：MLPClassifier**

以下是一個使用 `MLPClassifier` 進行二分類問題的範例：

```python
from sklearn.neural_network import MLPClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 創建一個簡單的分類數據集
X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)

# 將數據集拆分為訓練集和測試集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 初始化 MLPClassifier
mlp = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=500)

# 訓練模型
mlp.fit(X_train, y_train)

# 預測測試集
y_pred = mlp.predict(X_test)

# 評估模型
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")
```

在這個範例中，我們創建了一個包含 1000 個樣本和 20 個特徵的分類數據集，並使用 `MLPClassifier` 訓練模型。`hidden_layer_sizes` 設定了隱藏層的結構（100 個神經元和 50 個神經元），`activation` 設定激活函數為 `relu`，`solver` 使用 `adam` 優化器。

#### **(2) 基本範例：MLPRegressor**

同樣的，`MLPRegressor` 用於回歸問題的範例如下：

```python
from sklearn.neural_network import MLPRegressor
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# 創建一個簡單的回歸數據集
X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)

# 將數據集拆分為訓練集和測試集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 初始化 MLPRegressor
mlp_regressor = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=500)

# 訓練模型
mlp_regressor.fit(X_train, y_train)

# 預測測試集
y_pred = mlp_regressor.predict(X_test)

# 評估模型
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse:.4f}")
```

在這個範例中，我們使用 `MLPRegressor` 來解決回歸問題，並使用 `mean_squared_error` 來評估模型的預測性能。

---

### **2. scikit-learn 與神經網絡集成**

scikit-learn 提供了一些工具，使得我們可以將神經網絡與其他機器學習算法（如 `GridSearchCV`、`Pipeline` 等）結合使用，從而進行更加高效的模型選擇、調參和管道化操作。

#### **(1) 使用 GridSearchCV 調整超參數**

`GridSearchCV` 可以用來自動搜索超參數的最佳組合。下面是使用 `MLPClassifier` 和 `GridSearchCV` 進行超參數調整的範例：

```python
from sklearn.model_selection import GridSearchCV
from sklearn.neural_network import MLPClassifier

# 設置超參數搜索空間
param_grid = {
    'hidden_layer_sizes': [(50,), (100,), (50, 50)],
    'activation': ['relu', 'tanh'],
    'solver': ['adam', 'sgd'],
    'max_iter': [200, 500]
}

# 初始化 MLPClassifier
mlp = MLPClassifier()

# 使用 GridSearchCV 進行超參數搜索
grid_search = GridSearchCV(mlp, param_grid, cv=5, n_jobs=-1, verbose=1)

# 訓練模型
grid_search.fit(X_train, y_train)

# 輸出最佳參數
print(f"Best Parameters: {grid_search.best_params_}")
```

這樣可以根據不同的超參數選擇，幫助找到最合適的模型。

#### **(2) 使用 Pipeline 集成 MLP 模型**

`Pipeline` 是 scikit-learn 中的強大工具，它允許我們將數據預處理、特徵選擇、模型訓練等步驟組合在一起。以下是使用 `Pipeline` 組合 `MLPClassifier` 的範例：

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier

# 創建一個包含數據預處理和模型訓練的 Pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),  # 數據標準化
    ('mlp', MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=500))
])

# 訓練模型
pipeline.fit(X_train, y_train)

# 預測測試集
y_pred = pipeline.predict(X_test)

# 評估模型
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")
```

在這個範例中，我們將數據標準化和 MLP 模型放入一個管道中。這樣可以確保每次訓練過程中都進行正確的數據預處理，並且讓模型訓練過程更加簡潔。

---

### **3. 使用 MLP 與其他 scikit-learn 模型**

除了直接使用 `MLPClassifier` 和 `MLPRegressor`，您還可以將神經網絡與其他 scikit-learn 模型結合使用。例如，可以將 MLP 模型作為基礎模型的一部分，並使用集成方法（如 `VotingClassifier`、`StackingClassifier`）進行模型融合：

```python
from sklearn.ensemble import VotingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier

# 初始化三個模型
model1 = MLPClassifier(hidden_layer_sizes=(50,), activation='relu', solver='adam', max_iter=500)
model2 = SVC(kernel='linear', probability=True)
model3 = LogisticRegression()

# 使用 VotingClassifier 將三個模型融合
voting_clf = VotingClassifier(estimators=[('mlp', model1), ('svm', model2), ('logreg', model3)], voting='soft')

# 訓練模型
voting_clf.fit(X_train, y_train)

# 評估模型
y_pred = voting_clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Voting Classifier Accuracy: {accuracy:.4f}")
```

在這個範例中，我們使用了 `VotingClassifier` 來集成 MLP、SVM 和邏輯回歸模型，這樣能夠提高預測準確性，特別是在模型性能較為接近的情況下。

---

### **小結**

- **MLPClassifier 和 MLPRegressor** 是 scikit-learn 中用於分類和回歸問題的神經網絡模型。
- scikit-learn 提供了與神經網絡模型的集成工具，例如 `GridSearchCV` 進行超參數調