### **4. MLP架構與數學**
#### **神經元、層與網路結構**

在神經網絡（尤其是多層感知器，MLP）中，基礎的構建單位是神經元（Neuron）。神經網絡通常由數層組成，每層由多個神經元構成。這些神經元的排列形成了網絡的結構。以下是神經網絡架構的基本組成部分：神經元、層和網絡結構。

---

### **1. 神經元的結構**

每個神經元的基本功能是接收來自上一層的輸入，進行加權求和，並應用激勵函數產生輸出。

#### **數學表示：**

對於第 \( j \) 個神經元，輸入是來自上一層的信號 \( x_1, x_2, ..., x_n \)，每個輸入都有一個相應的權重 \( w_1, w_2, ..., w_n \)，還有一個偏置項 \( b \)。

該神經元的輸出 \( y_j \) 可以通過以下公式計算：

\[
z_j = w_1 x_1 + w_2 x_2 + \dots + w_n x_n + b
\]
\[
y_j = f(z_j)
\]

其中：
- \( w_1, w_2, ..., w_n \) 是權重，
- \( x_1, x_2, ..., x_n \) 是輸入，
- \( b \) 是偏置項，
- \( f(z_j) \) 是激勵函數（如 ReLU、Sigmoid、Tanh 等），用來增加非線性。

---

### **2. 層的結構**

神經網絡是由多層神經元組成的。常見的層有：

- **輸入層（Input Layer）**：接受外部數據作為輸入，並將其傳遞給下一層。
- **隱藏層（Hidden Layer）**：由多個神經元組成，通過學習從輸入層獲取的特徵，並將其傳遞到輸出層。這些層通常包含激勵函數以增加非線性。
- **輸出層（Output Layer）**：根據預測任務（如分類或回歸）給出最終的輸出結果。

在多層感知器（MLP）中，隱藏層是至關重要的部分，通常會有一個或多個隱藏層。每層都由若干神經元組成，這些神經元彼此相互連接，並通過權重進行調整。

#### **數學表示：**
假設有兩層神經網絡：
- 第一層的輸入為 \( x \)（維度為 \( n \)），權重矩陣為 \( W_1 \)（維度為 \( m \times n \)），偏置為 \( b_1 \)（維度為 \( m \)）。
- 第二層的輸出為 \( y \)（維度為 \( p \)），權重矩陣為 \( W_2 \)（維度為 \( p \times m \)），偏置為 \( b_2 \)（維度為 \( p \)）。

這時，前向傳播可以表示為：

- 第一層：
  \[
  z_1 = W_1 x + b_1
  \]
  \[
  a_1 = f_1(z_1)
  \]

- 第二層：
  \[
  z_2 = W_2 a_1 + b_2
  \]
  \[
  y = f_2(z_2)
  \]

其中：
- \( f_1 \) 和 \( f_2 \) 是第一層和第二層的激勵函數。

這樣的結構可以擴展到更深的網絡，通過增加更多的隱藏層來提高模型的表達能力。

---

### **3. 網路結構**

MLP的結構就是這些層的堆疊。每一層的神經元都與上一層的神經元連接，並根據權重學習。這樣的結構可以被視為一個函數的組合，每一層學習從輸入到輸出的映射。具體結構設計會根據實際任務而有所不同，通常會根據以下要素來決定：

- **層數**：即隱藏層的數量。較深的網絡（更多層）能夠學習更複雜的特徵，但也可能會更難訓練，並需要更多的計算資源。
- **每層神經元的數量**：每層的神經元數量會影響網絡的容量。較多的神經元能夠學習更多的特徵，但也可能增加過擬合的風險。

#### **層結構範例：**

- **單層網絡**：僅有一層隱藏層的簡單結構。
  ```
  Input Layer --> Hidden Layer --> Output Layer
  ```
- **多層網絡（深度神經網絡）**：有多層隱藏層的結構。
  ```
  Input Layer --> Hidden Layer 1 --> Hidden Layer 2 --> ... --> Output Layer
  ```

---

### **4. 重要概念**

- **激勵函數**（Activation Function）：用來引入非線性特徵，使得神經網絡能夠學習複雜的模式。常見的激勵函數包括：
  - **ReLU（Rectified Linear Unit）**：常用於隱藏層。
  - **Sigmoid**：適用於二分類問題的輸出層。
  - **Tanh**：在某些情況下比 Sigmoid 更適合，尤其是當數據需要進行標準化時。

- **權重和偏置**：每個神經元都有權重和偏置，用於調整輸入信號的強度和偏移。這些參數在訓練過程中進行更新。

- **前向傳播與反向傳播**：
  - **前向傳播**：將數據從輸入層傳遞到輸出層，並計算損失。
  - **反向傳播**：基於損失計算梯度，並通過梯度下降法更新權重和偏置。

---

### **總結**

- **神經元**是網絡的基本構建單位，每個神經元進行加權求和並通過激勵函數輸出結果。
- **層**由多個神經元組成，隱藏層將學到的特徵傳遞給下一層，最終的預測結果由輸出層給出。
- **網絡結構**是多層神經元的堆疊，隱藏層數量和每層神經元數量會影響模型的表達能力。
- **激勵函數**使得神經網絡能夠捕捉非線性特徵，是神經網絡中至關重要的元素。

這些基本組成部分和結構是設計和訓練 MLP 網絡的基礎，對於理解更複雜的神經網絡（如卷積神經網絡、循環神經網絡）也至關重要。ㄋ