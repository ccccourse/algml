### **13.3 自編碼器的應用：數據壓縮與降噪**

自編碼器（Autoencoder, AE）是一種無監督學習方法，它學會將輸入數據映射到較小的潛在空間（編碼），並從這些壓縮的表示中重建輸入數據（解碼）。由於其特性，自編碼器被廣泛應用於數據壓縮和降噪等領域。

#### **1. 數據壓縮**

數據壓縮是自編碼器的一個常見應用。自編碼器學會將高維數據映射到低維的潛在空間，使得重建過程能夠盡可能保留輸入數據的關鍵特徵。這樣可以實現數據的壓縮，使其佔用更少的存儲空間。

**自編碼器在數據壓縮中的運作原理：**
- **編碼過程：** 自編碼器將原始數據映射到潛在空間中的低維表示。這個過程可以理解為對數據的壓縮，保留了數據的最重要特徵。
- **解碼過程：** 自編碼器從潛在空間的低維表示中重建數據。重建的數據應該儘可能接近原始輸入。

在數據壓縮中，潛在空間的維度通常比輸入數據的維度小，這使得自編碼器能夠有效地壓縮數據。

**數據壓縮示例：**
自編碼器可以應用於圖像壓縮中，通過訓練一個自編碼器來將高解析度圖像壓縮成較小的潛在向量，再解碼生成壓縮後的圖像。

#### **2. 降噪**

自編碼器也可以用來進行圖像或信號的降噪。降噪自編碼器（Denoising Autoencoder, DAE）是一種自編碼器變體，它在訓練過程中故意對輸入數據添加噪聲，然後要求模型從噪聲數據中重建原始的無噪聲數據。這樣，降噪自編碼器學會了如何從雜訊中恢復清晰的數據。

**降噪自編碼器的原理：**
- 在訓練過程中，將噪聲加入到輸入數據中，然後訓練模型從含噪聲的數據中重建出清晰的數據。
- 編碼器學會在不完整或被污染的數據中提取有用的特徵。
- 解碼器則根據這些特徵生成去噪後的數據。

**降噪自編碼器應用示例：**
在圖像去噪中，假設我們有一幅含有高斯噪聲的圖像，降噪自編碼器會學習如何從噪聲圖像中恢復原始的清晰圖像。

### **實現降噪自編碼器（Denoising Autoencoder）**

以下是使用 PyTorch 實現降噪自編碼器的步驟：

#### 1. 定義降噪自編碼器模型

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

class DenoisingAutoencoder(nn.Module):
    def __init__(self, input_dim, latent_dim):
        super(DenoisingAutoencoder, self).__init__()
        
        # 編碼器
        self.fc1 = nn.Linear(input_dim, 512)
        self.fc2 = nn.Linear(512, latent_dim)
        
        # 解碼器
        self.fc3 = nn.Linear(latent_dim, 512)
        self.fc4 = nn.Linear(512, input_dim)
    
    def encode(self, x):
        h1 = F.relu(self.fc1(x))
        return F.relu(self.fc2(h1))
    
    def decode(self, z):
        h3 = F.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h3))  # 將輸出映射到[0, 1]範圍
    
    def forward(self, x):
        z = self.encode(x)  # 編碼
        return self.decode(z)  # 解碼
```

#### 2. 添加噪聲

為了訓練降噪自編碼器，我們需要對輸入數據添加噪聲。這裡以高斯噪聲為例：

```python
def add_noise(data, noise_factor=0.5):
    noise = torch.randn_like(data) * noise_factor  # 生成噪聲
    noisy_data = data + noise  # 添加噪聲
    return torch.clamp(noisy_data, 0., 1.)  # 限制範圍[0, 1]
```

#### 3. 訓練降噪自編碼器

```python
input_dim = 784  # 例如，28x28像素的圖像
latent_dim = 32  # 潛在空間的維度
model = DenoisingAutoencoder(input_dim, latent_dim)
optimizer = optim.Adam(model.parameters(), lr=1e-3)

num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    optimizer.zero_grad()
    
    # 假設有MNIST數據
    noisy_data = add_noise(X_train)  # 添加噪聲
    output = model(noisy_data)  # 自編碼器進行重建
    
    # 計算損失
    loss = F.mse_loss(output, X_train)  # 使用MSE損失進行重建
    
    loss.backward()
    optimizer.step()
    
    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')
```

#### 4. 測試與生成

在訓練完成後，模型能夠從含噪聲的數據中重建出清晰的數據。可以對新的含噪聲數據進行去噪：

```python
model.eval()  # 設置為評估模式
with torch.no_grad():
    noisy_test_data = add_noise(X_test)  # 為測試數據添加噪聲
    denoised_data = model(noisy_test_data)  # 生成去噪後的數據
```

---

### **總結**

自編碼器的應用之一是數據壓縮，它通過將數據映射到低維的潛在空間來減少數據的維度，從而實現數據的壓縮。另一個重要的應用是降噪，特別是降噪自編碼器（DAE），它能夠從帶噪聲的數據中學習如何重建出清晰的數據。自編碼器在圖像處理、信號處理等領域具有廣泛的應用。