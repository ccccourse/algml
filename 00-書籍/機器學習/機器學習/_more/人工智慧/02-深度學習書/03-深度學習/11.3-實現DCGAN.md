### **11.4 實現DCGAN（Deep Convolutional GAN）**

深度卷積生成對抗網絡（DCGAN）是一種改進的生成對抗網絡架構，專門用於生成高品質的圖像。相比於原始的GAN，DCGAN引入了卷積神經網絡（CNN）來作為生成器和判別器的基礎結構，這樣可以更有效地捕捉圖像的空間結構特徵，並生成更清晰的圖像。

在這裡，我們將使用 PyTorch 來實現一個簡單的 DCGAN，並訓練它來生成MNIST手寫數字圖像。

---

### **步驟 1：準備數據集**

我們將使用 MNIST 數據集來進行訓練，這是一個包含手寫數字圖像的常見數據集。

```python
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

# 定義數據轉換操作，將圖像轉換為張量並歸一化到[-1, 1]範圍
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

# 加載MNIST數據集
train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
```

---

### **步驟 2：定義生成器（Generator）**

生成器將一個隨機噪聲向量（通常是均勻分布或正態分布的隨機數字）轉換為假圖像。DCGAN中的生成器通常由多層轉置卷積（反卷積）構成，這些層可以將低維度的噪聲向量映射到高維度的圖像空間。

```python
import torch.nn as nn

class Generator(nn.Module):
    def __init__(self, z_dim):
        super(Generator, self).__init__()
        self.fc1 = nn.Linear(z_dim, 256)
        self.bn1 = nn.BatchNorm1d(256)
        self.fc2 = nn.Linear(256, 512)
        self.bn2 = nn.BatchNorm1d(512)
        self.fc3 = nn.Linear(512, 1024)
        self.bn3 = nn.BatchNorm1d(1024)
        self.fc4 = nn.Linear(1024, 1 * 28 * 28)

        # 轉換成28x28圖像
        self.final = nn.Tanh()

    def forward(self, z):
        x = torch.relu(self.bn1(self.fc1(z)))
        x = torch.relu(self.bn2(self.fc2(x)))
        x = torch.relu(self.bn3(self.fc3(x)))
        x = self.fc4(x)
        x = x.view(-1, 1, 28, 28)
        return self.final(x)
```

這裡的生成器架構由4個全連接層組成，其中每一層都進行激勵和批量正則化處理。最後，輸出會被轉換為28x28的圖像，並通過`Tanh`激活函數將像素值映射到 [-1, 1]。

---

### **步驟 3：定義判別器（Discriminator）**

判別器的任務是判斷輸入的圖像是真實的還是由生成器生成的偽圖像。DCGAN的判別器通常使用卷積層來學習圖像的特徵。

```python
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.conv1 = nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)
        self.conv4 = nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1)

        self.fc = nn.Linear(512 * 1 * 1, 1)
        self.final = nn.Sigmoid()

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.relu(self.conv2(x))
        x = torch.relu(self.conv3(x))
        x = torch.relu(self.conv4(x))
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return self.final(x)
```

判別器由四個卷積層組成，然後經過一個全連接層來決定輸入是“真”還是“假”。

---

### **步驟 4：訓練模型**

現在我們可以開始訓練生成器和判別器了。在訓練過程中，生成器會學習生成越來越真實的圖像，而判別器則會不斷提高區分真實圖像和生成圖像的能力。

```python
import torch.optim as optim

# 設定超參數
z_dim = 100  # 噪聲向量的維度
lr = 0.0002   # 學習率
betas = (0.5, 0.999)  # Adam優化器的參數

# 創建生成器和判別器
generator = Generator(z_dim)
discriminator = Discriminator()

# 使用Adam優化器
optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=betas)
optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)

# 損失函數
criterion = nn.BCELoss()

# 訓練過程
num_epochs = 50
for epoch in range(num_epochs):
    for i, (real_images, _) in enumerate(train_loader):
        batch_size = real_images.size(0)
        real_images = real_images.to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))
        
        # 標籤
        real_labels = torch.ones(batch_size, 1).to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))
        fake_labels = torch.zeros(batch_size, 1).to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))
        
        # 訓練判別器
        optimizer_d.zero_grad()
        
        # 訓練判別器識別真實圖像
        outputs = discriminator(real_images)
        d_loss_real = criterion(outputs, real_labels)
        
        # 訓練判別器識別生成圖像
        z = torch.randn(batch_size, z_dim).to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))
        fake_images = generator(z)
        outputs = discriminator(fake_images.detach())
        d_loss_fake = criterion(outputs, fake_labels)
        
        # 總損失
        d_loss = d_loss_real + d_loss_fake
        d_loss.backward()
        optimizer_d.step()
        
        # 訓練生成器
        optimizer_g.zero_grad()
        
        # 訓練生成器使得判別器分類假圖像為真
        outputs = discriminator(fake_images)
        g_loss = criterion(outputs, real_labels)
        
        g_loss.backward()
        optimizer_g.step()

    print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item()}, g_loss: {g_loss.item()}')
```

在訓練過程中，我們首先訓練判別器，讓它學會識別真實圖像和生成的假圖像。然後，我們訓練生成器，使其生成的假圖像能夠成功欺騙判別器。

---

### **步驟 5：生成圖像**

訓練完成後，我們可以使用訓練好的生成器來生成新圖像。

```python
import matplotlib.pyplot as plt

# 隨機噪聲
z = torch.randn(64, z_dim).to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))
fake_images = generator(z)

# 顯示生成的圖像
fake_images = fake_images.cpu().detach()
grid = torchvision.utils.make_grid(fake_images, nrow=8, normalize=True)
plt.imshow(grid.permute(1, 2, 0))
plt.show()
```

這段代碼會生成並顯示出來64張由生成器生成的假圖像。

---

### **總結**

DCGAN 是一種基於卷積網絡的生成對抗網絡架構，通過卷積層來提高生成的圖像質量，並且能夠有效地捕捉圖像的空間結構。在這個實現中，我們使用了 PyTorch 來構建和訓練生成器與判別器，並展示了如何生成高品質的圖像。