### **11.1 用 `nn.Sequential` 和自定義 `Generator` 和 `Discriminator` 類來定義模型**

在生成對抗網絡（GAN）的實現中，生成器（Generator）和判別器（Discriminator）通常可以用兩種方式來定義：一種是使用 `nn.Sequential` 來順序構建模型，另一種則是使用自定義的類來實現。以下將介紹如何使用這兩種方法來定義 GAN 的模型。

---

### **1. 使用 `nn.Sequential` 定義模型**

`nn.Sequential` 是 PyTorch 中的一個容器，允許將一系列層按順序組合起來。對於簡單的模型，我們可以使用 `nn.Sequential` 來簡化模型的定義，這種方法適合當模型的層結構很簡單，沒有太多的控制邏輯或分支結構。

#### **1.1 生成器（Generator）**

生成器的目標是生成假數據，它通常是由全連接層（`nn.Linear`）和激勵函數（例如 `ReLU`）組成，最終輸出與真實數據相同維度的數據。下面是用 `nn.Sequential` 定義生成器的一個例子：

```python
import torch
import torch.nn as nn

class Generator(nn.Module):
    def __init__(self, z_dim, img_dim):
        super(Generator, self).__init__()
        
        # 使用 nn.Sequential 定義生成器模型
        self.model = nn.Sequential(
            nn.Linear(z_dim, 128),     # 第一層：從潛在向量 z_dim 到 128 維度
            nn.ReLU(True),             # 激勵函數 ReLU
            nn.Linear(128, 256),       # 第二層：128 維到 256 維
            nn.ReLU(True),
            nn.Linear(256, 512),       # 第三層：256 維到 512 維
            nn.ReLU(True),
            nn.Linear(512, img_dim),   # 輸出層：512 維到圖像維度
            nn.Tanh()                  # 使用 Tanh 激勵函數，將輸出約束在 [-1, 1]
        )

    def forward(self, z):
        return self.model(z)
```

在這裡，`z_dim` 代表潛在向量的維度（例如，隨機噪聲向量的大小），`img_dim` 則是目標圖像的維度（例如，對於 28x28 像素的灰度圖像，`img_dim` 是 784）。生成器模型的目標是將潛在向量（噪聲）映射到一個假圖像。

#### **1.2 判別器（Discriminator）**

判別器的目標是區分真實圖像和生成的圖像。通常，判別器由多層全連接層組成，最後通過 Sigmoid 激勵函數將輸出限制在 [0, 1] 範圍內，代表該圖像是否為真實圖像。

```python
class Discriminator(nn.Module):
    def __init__(self, img_dim):
        super(Discriminator, self).__init__()
        
        # 使用 nn.Sequential 定義判別器模型
        self.model = nn.Sequential(
            nn.Linear(img_dim, 512),    # 第一層：從圖像維度到 512 維
            nn.LeakyReLU(0.2, inplace=True),  # 激勵函數 LeakyReLU
            nn.Linear(512, 256),        # 第二層：512 維到 256 維
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 128),        # 第三層：256 維到 128 維
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(128, 1),          # 輸出層：從 128 維到 1，輸出真假判斷
            nn.Sigmoid()                # Sigmoid 函數，將輸出限制在 [0, 1] 範圍
        )

    def forward(self, x):
        return self.model(x)
```

這裡，`img_dim` 是圖像的維度（例如 784，對應 28x28 的灰度圖像），`LeakyReLU` 激勵函數常用於判別器，因為它可以避免神經元死亡（即 ReLU 輸出始終為零的情況）。

---

### **2. 使用自定義 `Generator` 和 `Discriminator` 類定義模型**

當模型結構較為複雜，或是需要更細緻的控制（例如分支、循環等）時，通常會使用自定義的類來定義生成器和判別器。這樣我們可以更靈活地定義各種層級和前向傳播邏輯。

#### **2.1 生成器（Generator）**

```python
class Generator(nn.Module):
    def __init__(self, z_dim, img_dim):
        super(Generator, self).__init__()
        self.fc1 = nn.Linear(z_dim, 256)   # 第一層：全連接層
        self.fc2 = nn.Linear(256, 512)     # 第二層：全連接層
        self.fc3 = nn.Linear(512, 1024)    # 第三層：全連接層
        self.fc4 = nn.Linear(1024, img_dim) # 輸出層

        self.relu = nn.ReLU(True)
        self.tanh = nn.Tanh()

    def forward(self, z):
        x = self.relu(self.fc1(z))  # 激勵函數
        x = self.relu(self.fc2(x))
        x = self.relu(self.fc3(x))
        return self.tanh(self.fc4(x))  # 輸出假圖像
```

#### **2.2 判別器（Discriminator）**

```python
class Discriminator(nn.Module):
    def __init__(self, img_dim):
        super(Discriminator, self).__init__()
        self.fc1 = nn.Linear(img_dim, 1024)   # 第一層
        self.fc2 = nn.Linear(1024, 512)       # 第二層
        self.fc3 = nn.Linear(512, 256)        # 第三層
        self.fc4 = nn.Linear(256, 1)          # 輸出層

        self.leaky_relu = nn.LeakyReLU(0.2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.leaky_relu(self.fc1(x))  # 激勵函數
        x = self.leaky_relu(self.fc2(x))
        x = self.leaky_relu(self.fc3(x))
        return self.sigmoid(self.fc4(x))  # 輸出真假判斷
```

在這裡，`forward` 方法定義了數據流過模型時的處理流程。`LeakyReLU` 和 `Sigmoid` 分別用於隱藏層和輸出層的激勵。

---

### **3. 模型訓練循環**

無論使用 `nn.Sequential` 還是自定義類，訓練生成對抗網絡的循環都非常類似。首先需要定義損失函數（通常使用交叉熵損失），然後對生成器和判別器進行交替優化。

```python
# 訓練過程的簡單框架
import torch.optim as optim

# 初始化生成器和判別器
z_dim = 100
img_dim = 784  # 28x28圖像
generator = Generator(z_dim, img_dim)
discriminator = Discriminator(img_dim)

# 定義損失函數和優化器
criterion = nn.BCELoss()
lr = 0.0002
optim_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
optim_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

# 訓練循環 (伪代码示例)
for epoch in range(num_epochs):
    for real_images, _ in dataloader:
        # --- 判別器訓練 ---
        optim_D.zero_grad()
        
        # 虛擬圖像的訓練
        fake_images = generator(z)
        real_labels = torch.ones(batch_size, 1)  # 真實圖像標籤
        fake_labels = torch.zeros(batch_size, 1)  # 假圖像標籤
        
        real_loss = criterion(discriminator(real_images), real_labels)
        fake_loss = criterion(discriminator(fake_images.detach()), fake_labels)
        d_loss = real_loss + fake_loss
        d_loss.backward()
        optim_D.step()
        
        # --- 生成器訓練 ---
        optim_G.zero_grad()
        g_loss = criterion(discriminator(fake_images), real_labels)  # 生成器希望判別器把假圖像識別為真
        g_loss.backward()
        optim_G.step()
```

這樣，我們就完成了 GAN 的基本模型定義，並且具備了訓練的基本框架。