### **CNN模型訓練實例：圖像分類**

在這個部分，我們將使用之前定義的卷積神經網絡（CNN）模型來訓練一個簡單的圖像分類任務。我們會使用 PyTorch 提供的數據集來進行訓練，並展示如何進行圖像分類模型的訓練過程。

我們的例子將使用 **CIFAR-10** 數據集，它包含 10 個類別的圖像，每個類別有 6,000 張 32x32 像素的圖像。這是經典的圖像分類任務，非常適合用來訓練卷積神經網絡。

### **1. 安裝必要的庫**

首先確保安裝了 PyTorch 和 torchvision。可以使用以下命令來安裝：
```bash
pip install torch torchvision
```

### **2. 加載數據集**

使用 PyTorch 的 `torchvision.datasets` 來加載 CIFAR-10 數據集。這個數據集包含了 10 類常見物體（如汽車、飛機、貓、狗等）的圖像。我們將加載訓練集和測試集，並進行一些基本的圖像預處理（如標準化和轉換為張量）。

```python
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

# 定義圖像轉換操作：標準化與轉換為Tensor
transform = transforms.Compose([
    transforms.ToTensor(),  # 將圖像轉換為 Tensor
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 標準化
])

# 下載並加載 CIFAR-10 訓練集
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = DataLoader(trainset, batch_size=64, shuffle=True)

# 下載並加載 CIFAR-10 測試集
testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = DataLoader(testset, batch_size=64, shuffle=False)
```

### **3. 定義CNN模型**

使用我們之前定義的 `SimpleCNN` 類來建立 CNN 模型。這個模型包括卷積層、池化層和全連接層。

```python
import torch.nn as nn
import torch.optim as optim

# 定義 CNN 模型（如前所述）
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        
        self.conv1 = nn.Conv2d(3, 32, 3, 1, 1)  # 卷積層1
        self.pool1 = nn.MaxPool2d(2, 2)         # 池化層1
        
        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1) # 卷積層2
        self.pool2 = nn.MaxPool2d(2, 2)         # 池化層2
        
        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1) # 卷積層3
        self.pool3 = nn.MaxPool2d(2, 2)          # 池化層3
        
        self.fc1 = nn.Linear(128 * 4 * 4, 512)    # 全連接層1
        self.fc2 = nn.Linear(512, 10)             # 輸出層（10個類別）

    def forward(self, x):
        x = self.pool1(torch.relu(self.conv1(x)))
        x = self.pool2(torch.relu(self.conv2(x)))
        x = self.pool3(torch.relu(self.conv3(x)))
        
        x = x.view(-1, 128 * 4 * 4)  # 展平
        x = torch.relu(self.fc1(x))  # 全連接層
        x = self.fc2(x)             # 輸出
        return x

# 初始化模型
model = SimpleCNN()
```

### **4. 訓練模型**

定義損失函數和優化器，並進行模型訓練。這裡使用的是交叉熵損失函數（`CrossEntropyLoss`）和 Adam 優化器。

```python
# 定義損失函數和優化器
criterion = nn.CrossEntropyLoss()  # 交叉熵損失
optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 優化器

# 訓練循環
num_epochs = 10  # 訓練10個epoch
for epoch in range(num_epochs):
    running_loss = 0.0
    for i, (inputs, labels) in enumerate(trainloader, 0):
        # 訓練過程
        optimizer.zero_grad()  # 清除過去的梯度
        
        outputs = model(inputs)  # 前向傳播
        loss = criterion(outputs, labels)  # 計算損失
        loss.backward()  # 反向傳播
        optimizer.step()  # 更新權重
        
        running_loss += loss.item()
        if i % 100 == 99:    # 每100個批次打印一次損失
            print(f"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}")
            running_loss = 0.0

print("訓練完成")
```

### **5. 測試模型**

在測試集上評估模型的表現，計算其準確率。

```python
# 測試模型
correct = 0
total = 0
with torch.no_grad():  # 在測試時禁用梯度計算
    for inputs, labels in testloader:
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)  # 預測類別
        total += labels.size(0)  # 總數量
        correct += (predicted == labels).sum().item()  # 計算正確的預測數量

accuracy = 100 * correct / total
print(f"測試準確率: {accuracy:.2f}%")
```

### **6. 完整代碼**

```python
import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

# 加載數據集
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = DataLoader(trainset, batch_size=64, shuffle=True)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = DataLoader(testset, batch_size=64, shuffle=False)

# 定義CNN模型
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, 1, 1)
        self.pool1 = nn.MaxPool2d(2, 2)
        
        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)
        self.pool2 = nn.MaxPool2d(2, 2)
        
        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)
        self.pool3 = nn.MaxPool2d(2, 2)
        
        self.fc1 = nn.Linear(128 * 4 * 4, 512)
        self.fc2 = nn.Linear(512, 10)

    def forward(self, x):
        x = self.pool1(torch.relu(self.conv1(x)))
        x = self.pool2(torch.relu(self.conv2(x)))
        x = self.pool3(torch.relu(self.conv3(x)))
        
        x = x.view(-1, 128 * 4 * 4)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# 訓練模型
model = SimpleCNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 訓練過程
num_epochs = 10
for epoch in range(num_epochs):
    running_loss = 0.0
    for i, (inputs, labels) in enumerate(trainloader, 0):
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        if i % 100 == 99:
            print(f"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}")
            running_loss = 0.0

print("訓練完成")

# 測試模型
correct = 0
total = 0
with torch.no_grad():
    for inputs, labels in testloader:
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

accuracy = 100 * correct / total
print(f"測試準確率: {accuracy:.2f}%")
```

### **總結**

我們使用 PyTorch 實現了一個簡單的 CNN 模型來進行 CIFAR-10 圖像分類。訓練過程中，我們計算了每個批次的損失，並在完成訓練後評估了測試集上的準確率。這是一個典型的 CNN 訓練實例，適用於圖像分類任務。