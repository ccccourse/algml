### **3. PyTorch 基礎**
#### **張量的基本操作**

PyTorch 中的 **張量 (Tensor)** 是一個多維矩陣的資料結構，可以包含任意數量的維度。張量在 PyTorch 中非常重要，它是進行數學運算和神經網路訓練的基本單位。PyTorch 提供了豐富的操作來處理張量。

---

### **1. 張量的創建**

在 PyTorch 中，我們可以使用 `torch.tensor()`、`torch.zeros()`、`torch.ones()`、`torch.rand()` 等函數來創建張量。

#### **創建一個張量**
```python
import torch

# 創建一個 2x3 的張量，元素初始化為 0
x = torch.zeros(2, 3)
print(x)

# 創建一個 2x3 的張量，元素初始化為 1
y = torch.ones(2, 3)
print(y)

# 創建一個 2x3 的張量，元素初始化為隨機數字
z = torch.rand(2, 3)
print(z)

# 使用 Python list 創建張量
a = torch.tensor([[1, 2, 3], [4, 5, 6]])
print(a)
```

#### **指定張量類型**
PyTorch 提供了多種數據類型（`float32`, `int64` 等）。可以在創建時指定類型。
```python
b = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)
print(b)
```

---

### **2. 張量的基本操作**

PyTorch 提供了許多操作來對張量進行操作，這些操作包括數學運算、重塑、索引等。

#### **數學運算**
- **加法**：
```python
x = torch.tensor([1, 2])
y = torch.tensor([3, 4])
z = x + y  # 或者 z = torch.add(x, y)
print(z)  # Output: tensor([4, 6])
```

- **減法**：
```python
z = x - y  # 或者 z = torch.sub(x, y)
print(z)  # Output: tensor([-2, -2])
```

- **乘法**：
```python
z = x * y  # 或者 z = torch.mul(x, y)
print(z)  # Output: tensor([3, 8])
```

- **除法**：
```python
z = x / y  # 或者 z = torch.div(x, y)
print(z)  # Output: tensor([0.3333, 0.5000])
```

- **矩陣乘法**：
```python
a = torch.tensor([[1, 2], [3, 4]])
b = torch.tensor([[5, 6], [7, 8]])
z = torch.matmul(a, b)
print(z)
```

#### **轉置操作**
- **矩陣轉置**：
```python
a = torch.tensor([[1, 2], [3, 4]])
z = a.t()  # 或者 z = a.transpose(0, 1)
print(z)
```

---

### **3. 張量的索引與切片**

PyTorch 支援類似於 NumPy 的索引與切片操作。

#### **單個元素索引**
```python
x = torch.tensor([1, 2, 3, 4, 5])
print(x[2])  # Output: tensor(3)
```

#### **切片操作**
```python
x = torch.tensor([1, 2, 3, 4, 5])
print(x[1:4])  # Output: tensor([2, 3, 4])
```

#### **多維張量索引**
```python
a = torch.tensor([[1, 2], [3, 4], [5, 6]])
print(a[1, 1])  # Output: tensor(4)
print(a[:, 0])  # Output: tensor([1, 3, 5])
```

---

### **4. 張量重塑與改變形狀**

我們可以使用 `view()` 或 `reshape()` 改變張量的形狀，這在神經網路中尤其常見。

#### **使用 `view()` 重新塑形**
```python
a = torch.tensor([[1, 2], [3, 4], [5, 6]])
b = a.view(2, 3)  # 將 (3, 2) 形狀的張量轉為 (2, 3)
print(b)
```

#### **使用 `reshape()` 重新塑形**
```python
b = a.reshape(2, 3)
print(b)
```

#### **展平張量**
```python
a = torch.tensor([[1, 2], [3, 4], [5, 6]])
b = a.view(-1)  # -1 表示自動推斷該維度大小
print(b)  # Output: tensor([1, 2, 3, 4, 5, 6])
```

---

### **5. 張量的比較與條件操作**

PyTorch 支援張量的比較操作，例如 `>`, `<`, `==` 等。

#### **比較操作**
```python
x = torch.tensor([1, 2, 3])
y = torch.tensor([3, 2, 1])
print(x > y)  # Output: tensor([False, False, True])
```

#### **條件過濾**
可以使用布林值來過濾張量中的元素。
```python
x = torch.tensor([1, 2, 3, 4])
print(x[x > 2])  # Output: tensor([3, 4])
```

---

### **6. 張量的連接與堆疊**

#### **堆疊操作**
PyTorch 提供了多種方式來堆疊張量，如 `torch.cat()`、`torch.stack()`。

- **使用 `torch.cat()` 連接**
```python
a = torch.tensor([1, 2])
b = torch.tensor([3, 4])
c = torch.cat((a, b))  # 按列連接
print(c)  # Output: tensor([1, 2, 3, 4])
```

- **使用 `torch.stack()` 堆疊**
```python
a = torch.tensor([1, 2])
b = torch.tensor([3, 4])
c = torch.stack((a, b))  # 沿著新的維度堆疊
print(c)  # Output: tensor([[1, 2], [3, 4]])
```

---

### **7. 其他常用張量操作**

#### **張量的標準化與正規化**

- **標準化**：減去均值，除以標準差。
```python
x = torch.tensor([1., 2., 3., 4., 5.])
mean = x.mean()
std = x.std()
normalized_x = (x - mean) / std
print(normalized_x)
```

- **正規化**：將張量的值縮放到指定範圍內。
```python
x = torch.tensor([1., 2., 3., 4., 5.])
normalized_x = (x - x.min()) / (x.max() - x.min())
print(normalized_x)
```

---

### **總結**

在 PyTorch 中，張量是進行所有計算和模型訓練的基本單位。掌握張量的創建、操作、索引、重塑等基本操作是理解和使用 PyTorch 的基礎。這些基本操作將幫助你高效地處理數據並構建各種深度學習模型。