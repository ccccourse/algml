## 2.3. Gym 的基本結構

Gym 是一個開源的 Python 套件，可以用來開發和比較強化學習算法。在 Gym 中，每個強化學習問題都被建模為一個環境（environment），代理（agent）與環境互動，進行學習，環境通過系列的狀態（state）和行為（action）與代理進行交互，代理通過觀察環境狀態並執行行動來得到回饋信號（reward），目標是最大化回饋信號的累加和。Gym 提供了多種不同的環境和問題，並且支持模擬器和仿真器，可以輕鬆地在強化學習算法之間進行比較。

在 Gym 中，環境是指代理進行學習和交互的場景，如 CartPole （小車平衡杆問題）、MountainCar（山車問題）、Atari（雅達利遊戲）等。環境可以看作是一個黑盒子，代理通過觀察環境狀態和執行行為得到相應的回饋。在 Gym 中，環境統一的接口為 `Env`，可以通過以下方式獲得環境：

```python
import gym
env = gym.make('CartPole-v0')
```

其中，`'CartPole-v0'` 代表環境的識別符號（ID），代表 CartPole 問題的一個版本。使用 `gym.make()` 來創建一個環境實例。

在處理強化學習問題時，我們通常定義一個區間 R 表示環境中的回饋信號的取值範圍。在 Gym 中，環境回饋信號的取值範圍通過環境的屬性設定。在 CartPole 問題中，回饋信號的取值範圍為 [-inf, +inf]，可以通過以下方式獲得：

```python
print(env.action_space)
# Discrete(2)
print(env.observation_space)
# Box(4,)
print(env.reward_range)
# (-inf, inf)
```

`env.action_space` 返回了代理的可行動作空間，這些動作可以透過後續的 `env.step()` 函數來實際執行，`env.observation_space` 指定了代理感知到的環境的狀態空間。對於 CartPole 問題而言，代理可執行的動作只有 2 種（向左或向右），且代理的狀態由 Box 空間 4 個連續的實數值描述（分別代表小車和杆子的位置、速度、角度以及旋轉速度），回饋信號的取值範圍為 [-inf, +inf]。

Gym 提供了一個簡單的 API 來與環境進行交互，主要包括以下 3 種函數：

```python
observation = env.reset()   # 環境的初始化
observation, reward, done, info = env.step(action)   # 環境的運行及互動
env.render()               # 環境的顯示
```

其中，`env.reset()` 用於初始化環境，返回代理的初始狀態。`env.step(action)` 用於執行代理的動作，並返回四個值，其中 `observation` 是下一個狀態， `reward` 是代理由執行該動作而獲得的回饋信號， `done` 是一個布尔型變數，表示代理是否完成了目標任務， `info` 是一個字典型變數，可以用來存儲一些額外的資訊。最後，`env.render()` 用於讓環境顯示出當前所處的狀態。注意，在某些環境下，執行 `env.render()` 該操作可能會導致系統異常，所以要小心使用。

下面以 CartPole 問題為例，展示如何與環境進行互動：

```python
import gym

# 創建環境
env = gym.make('CartPole-v0')

# 重置環境，得到起始狀態
observation = env.reset()

# 環境運行，最多執行 100 步
for t in range(100):
    env.render()
    action = env.action_space.sample()  # 隨機選擇一個動作
    observation, reward, done, info = env.step(action)  # 執行動作並返回環境的下一個狀態和相應的回饋信號
    if done:
        print("Episode finished after {} timesteps".format(t+1))
        break
```

在上述程式碼中，我們創建了一個 CartPole-v0 環境，並進行了 100 步的操作，從而利用 `env.render()` 將運行過程顯示出來，然後隨機選擇一個動作，執行 `env.step()` 函數實際執行此動作，不斷地重複以上步驟，直到代理完成任務或者到達最大時步數。