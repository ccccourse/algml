## 2.2 線性回歸

線性回歸是一種監督式學習方法，用於對具有線性關係的資料建立一個線性模型。線性回歸試圖找到一條線（在 2D 空間中）或一個超平面（在較高維度中）來逼近資料。這條線/超平面最小化了實際資料與預測資料之間的平均距離，並且這個方法通過最小化均方差來達成目標。

均方誤差（Mean Squared Error，MSE）表示實際輸入值和模型預測值之間誤差的平方總和的平均值。在線性回歸中，該指標用於衡量模型的準確性。當 MSE 越小，表明模型擬合效果越好，預測結果越準確。

在 scikit-learn 中，使用`LinearRegression`類進行線性回歸建模。以下是一個簡單的範例程式碼，該程式碼使用 scikit-learn 中的線性回歸模型對一個 2D 數據集進行擬合：

```python
from sklearn.linear_model import LinearRegression
import numpy as np
import matplotlib.pyplot as plt

# 產生假數據
x = np.linspace(-10, 10, 100)
y = 3*x + np.random.randn(x.shape[0]) * 5   # 加上隨機雜訊

# 將數據格式化為矩陣
X = x[:, np.newaxis]

# 建立線性回歸模型
model = LinearRegression()

# 擬合模型
model.fit(X, y)

# 取得預測結果
y_pred = model.predict(X)

# 視覺化結果
plt.scatter(x, y, color='blue')
plt.plot(x, y_pred, color='red')
plt.show()
```

此程式構建了一個大小為 (100, 1) 的矩陣 X 作為模型的自變量，並用隨機生成的偏移量建立對應的因變量 y。接下來，使用 `fit()` 方法擬合線性模型。最後，使用 `predict()` 方法將自變量傳遞給模型，並獲取對應的因變量預測值。最後，將假數據的實際值和預測值視覺化以便進行比較。

可以看到，使用 scikit-learn 的線性回歸模型可以輕鬆對線性（一次多項式）關係進行建模和預測。當然，線性回歸也可以用於更高次元度的資料，包括多個自變量。