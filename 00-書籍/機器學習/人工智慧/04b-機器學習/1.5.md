## 1.5 模型選擇與評估

模型選擇是指從各種模型中選出最好的模型。模型評估則是通過分析模型的性能和表現如何，來測試模型是否符合其設計目的。在機器學習算法的世界中，模型選擇和評估是一項非常重要的工作。

機器學習中常用的評估指標如下：

1. 準確率（Accuracy）：是分類模型最常用的指標。準確率的計算方式是將分類模型預測正確的分類數量除以測試數據集中的總個數。準確率越高，說明模型的性能越好。但是，在存在類別不平衡的情況下，準確率可能並不是一個很好的度量指標。比如，在一個數據集中，正例和反例的比例是1:9，如果全部預測為反例的時候，因為反例的數量太多了，可以達到 90% 的準確率，但是這顯然是一個無用的模型。

2. 精確率（Precision）和召回率（Recall）: 準確率只考慮了分類結果預測正例的準確性，它無法告訴我們分類器判定了多少個正確的正例。如果我們的模型只判定一個，那麽準確率為 $100\%$。因此我們需要召回率和精確率來補充準確率的不足。精確率反映的是所有被判定為正例的數據中，真實為正例的占比；而召回率則反映了真正為正例的數據有多少被判定為正例。精確率和召回率計算方式如下

$$
精確率=\frac{TP}{TP+FP} \qquad 召回率=\frac{TP}{TP+FN}
$$

其中， $TP$ 表示真實正例被預測為正例的數量， $FP$ 表示在實際為負例的數據中被誤判為正例的數量， $FN$ 表示在實際為正例的數據中被誤判為負例的數量。更直觀的說，精確率是在所有預測成P的數據中，P 所占的比例。而召回率是在所有實際是P的數據中，預測為P的結果所占的比例。

3. F1 分數（F1-Score）：F1 分數是精確率和召回率的加權平均值，用於綜合考慮召回率和精確率，即 $F1=\frac{2}{precision^{-1} + recall^{-1}}=2 \frac{precision \times recall}{precision + recall}$ ，其中 precision 和 recall 分別代表精確率和召回率。

4. 平均絕對誤差（MAE）和均方誤差（MSE）：用於評估回歸模型。MAE 是預測值與真實值之差的絕對值的平均值，MSE 是預測值與真實值之差的平方的平均值。

在 scikit-learn 中，可以使用 `cross_validate` 方法進行 k 折交叉驗證，以確保所選擇的模型是穩健的。交叉驗證可以幫助我們評估模型在不同數據集上的表現。除此之外還可以通過其他一些方法來評估模型的性能表現，例如 confusion matrix、ROC 曲線等，scikit-learn 中也為我們提供了相應的工具。