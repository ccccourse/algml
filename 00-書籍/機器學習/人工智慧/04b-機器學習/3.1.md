## 3.1 非監督式學習簡介

非監督式學習是指在資料集中找尋其內在結構或規律，透過分群(Clustering)、降維(Dimensionality Reduction)等方式來找尋資料集中的模式或特徵，進而找出資料集中的有用資訊，也可以用來進行資料壓縮或去噪處理。

與監督式學習最大的差別在於，非監督式學習的樣本資料並沒有反應標籤 (Label)，因此需要使用者自行找尋規律或樣式。

非監督式學習可以適用於許多領域，例如生物資訊學、自然語言處理、圖形辨識、情感分析等等。

Scikit-Learn 中提供了許多非監督式學習的演算法，以下以幾個常用的演算法為例。

### 3.1.1 分群演算法

#### K-means 分群演算法

K-means 是一個經典且簡單的分群演算法，其就是從數據點集中找尋 K 個代表點，稱為聚類中心 (Cluster Center)，以最小化所有數據點與聚類中心之間的歐氏距離之和為目標。K-means 的流程如下：

1. 在數據點集中隨機選擇 K 個點作為初始的聚類中心。
2. 將其他的數據點依據聚類中心最近的距離歸類到不同的聚類中。
3. 重新計算每一群的聚類中心，計算方式為該聚類中所有點的平均值。
4. 重複進行步驟 2, 3，直到聚類中心不再改變或達到了預設的最大迭代次數為止。

K-means 的 Scikit-Learn 實現方式如下：

```python

from sklearn.cluster import KMeans

# 資料前處理
data = # 待分群數據
X = # 資料特徵
y = # 資料標籤

# 建立 KMeans 物件，K 值為 8，其它參數使用預設值
kmeans = KMeans(n_clusters=8)

# 訓練模型
kmeans.fit(X)

# 取得聚類結果
labels = kmeans.labels_

```

#### 層次分群

層次分群是另一種常用的分群演算法，與 K-means 不同之處在於，K-means 尋找的是 K 個聚類中心，而層次分群是透過聚合和分裂階段進行分群。層次分群演算法的分類方式有兩種，分別是凝聚式層次分群與分裂式層次分群。

凝聚式層次分群：從每個點開始，建立由一個點組成的初始群，然後將距離最近的兩群聚合在一起，如此重複直到萬物互聯、形成一個大的群為止。

分裂式層次分群：從所有點所在的一個大群起始，每次把最不相似的子群分成兩個更小的子群，直到每個子群的節點都是單獨的數據點。

Scikit-Learn 中實現層次分群的方式如下：

```python

from sklearn.cluster import AgglomerativeClustering

# 資料前處理
data = # 待分群數據
X = # 資料特徵
y = # 資料標籤

# 建立 AgglomerativeClustering 物件，K 值為 3，使用 Ward 作為相似度度量方式
agg_clf = AgglomerativeClustering(n_clusters=3, linkage='ward')

# 訓練模型
agg_clf.fit(X)

# 取得聚類結果
labels = agg_clf.labels_

```

### 3.1.2 降維演算法

降維是一種在保持數據集特徵的同時，減少數據集維度的技術。降維可以幫助將高維數據映射到低維空間，同時保持數據集的結構和特性。使用降維可以有以下優點：

* 可以減少原始數據集的儲存空間和計算所需的計算時間。
* 可以避免過度擬合的問題，有助於模型的泛化能力。
* 可以簡化模型和可視化複雜數據。

Scikit-Learn 中實現了許多的降維演算法，這裡介紹兩種較為常用的降維演算法。

#### 主成分分析

主成分分析(PCA)是一種廣泛應用於數據降維的演算法，其可將高維度數據投影到低維空間。與其他的降維演算法的需求不同，PCA 不需要事先知道目標維度的數量，而是將數據投影到一個子空間上，該子空間是所有數據維度中方差最大的方向。 PCA 的 Scikit-Learn 實現方式如下：

```python

from sklearn.decomposition import PCA

# 資料前處理
data = # 待降維數據
X = # 資料特徵
y = # 資料標籤

# 建立 PCA 物件，n_components 為樣本映射到的維度
pca = PCA(n_components=2)

# 訓練模型
X_pca = pca.fit_transform(X)

```

#### t-SNE

t-SNE (t-Distributed Stochastic Neighbor Embedding) 是一種流行的數據可視化技術，其可將高維數據點嵌入到一個低維空間，通常是二維平面。不同於 PCA 的線性點對點映射，t-SNE 通過將兩個點之間概率分布的相似性映射到低維空間中，從而保留了全局結構的重要信息。t-SNE 的 Scikit-Learn 實現方式如下：

```python

from sklearn.manifold import TSNE

# 資料前處理
data = # 待降維數據
X = # 資料特徵
y = # 資料標籤

# 建立 TSNE 物件，n_components 為嵌入空間維度
tsne = TSNE(n_components=2, init='pca', random_state=0)

# 將數據嵌入到二維空間中
X_tsne = tsne.fit_transform(X)

```