## 4.1 過擬合和欠擬合

在機器學習中，模型的訓練目的是通過學習訓練數據中的關係來捕捉輸入和輸出之間的映射，進而對未知的測試數據進行預測。然而，如果模型太過複雜，可能會在訓練數據上表現得很好，但在測試數據上表現得很差，這種情況被稱為過擬合。相反，如果模型太過簡單，可能會將訓練數據中的關係學習得不夠好，這種情況被稱為欠擬合。

![overfitting_underfitting](https://cdn-images-1.medium.com/max/800/1*ZkDLnt3fT0d4fMzfGkwJrg.png)

Scikit-Learn 中的許多模型都有過擬合和欠擬合的問題。解決這些問題的方法之一是調整模型的超參數以找到一個好的平衡點。超參數是在訓練之前需要手動設置的一些參數。下面是一些方法，可以通過 scikit-learn 來幫助您診斷和解決過擬合和欠擬合問題。

### 4.1.1 學習曲線

學習曲線是一個人工制定的解決方案，可以幫助您確定模型是過度擬合還是欠擬合。它將模型的訓練和測試準確度作為訓練數據大小的函數進行繪製。一旦該曲線趨於穩定，您就可以確定該模型是過度擬合還是欠擬合。

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve

def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,
                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):
    """
    Generate a simple plot of the test and training learning curve.

    Parameters
    ----------
    estimator : object type that implements the "fit" and "predict" methods
        An object of that type which is cloned for each validation.

    title : string
        Title for the chart.

    X : array-like, shape (n_samples, n_features)
        Training vector, where n_samples is the number of samples and
        n_features is the number of features.

    y : array-like, shape (n_samples) or (n_samples, n_features), optional
        Target relative to X for classification or regression;
        None for unsupervised learning.

    ylim : tuple, shape (ymin, ymax), optional
        Defines minimum and maximum yvalues plotted.

    cv : int, cross-validation generator or an iterable, optional
        Determines the cross-validation splitting strategy.
        Possible inputs for cv are:

          - None, to use the default 5-fold cross-validation,
          - integer, to specify the number of folds.
          - An object to be used as a cross-validation generator.
          - An iterable yielding train/test splits.

        For integer/None inputs, if ``y`` is binary or multiclass,
        :class:`StratifiedKFold` used. If the estimator is not a classifier
        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.

        Refer :ref:`User Guide <cross_validation>` for the various
        cross-validators that can be used here.

    n_jobs : int or None, optional (default=None)
        Number of jobs to run in parallel.
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`
        for more details.

    train_sizes : array-like, shape (n_ticks,), dtype float or int
        Relative or absolute numbers of training examples that will be used to
        generate the learning curve. If the dtype is float, it is regarded as a
        fraction of the maximum size of the training set (that is determined
        by the selected validation method), i.e. it has to be within (0, 1].
        Otherwise it is interpreted as absolute sizes of the training sets.
        Note that for classification the number of samples usually have to be
        big enough to contain at least one sample from each class.

    # Return
    # ------
    # plt.figure()
    # title : str 作圖標題
    # n : int 訓練集樣本個數
    # train_scores : array, shape (n_ticks, n_cv_folds) 訓練集 cross validation 評分
    # test_scores : array, shape (n_ticks, n_cv_folds) 测试集 cross validation 評分
    # no scoring callable passed 學習模型的方法
    # line : matplotlib.containers.Line2D, 表示學習曲線的線
    """
    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    train_sizes, train_scores, test_scores, _, _ = \
        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,
                       train_sizes=train_sizes,
                       scoring='accuracy')
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Training score")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Cross-validation score")

    plt.legend(loc="best")
    return plt, title, train_sizes, train_scores, test_scores, None, None
```

### 4.1.2 驗證曲線

驗證曲線顯示了您的模型在不同超參數值下的表現情況。它將模型的訓練和測試準確度作為參數值的函數進行繪製。隨著超參數的增加，會發現有些情況下會變得過度擬合，有些情況下會變得欠擬合。如果您注意到模型處於過度擬合狀態，那麼您需要調整模型的超參數以使其正確。

```python
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import validation_curve

def plot_validation_curve(estimator, title, X, y, param_name, param_range,
                          ylim=None, cv=None, n_jobs=None):

    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel(param_name)
    plt.ylabel("Score")
    train_scores, test_scores = validation_curve(
        estimator, X, y, param_name=param_name, param_range=param_range,
        cv=cv, scoring="accuracy", n_jobs=n_jobs)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    lw = 2
    plt.plot(param_range, train_scores_mean, label="Training score",
                 color="darkorange", lw=lw)
    plt.fill_between(param_range, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.2,
                     color="darkorange", lw=lw)
    plt.plot(param_range, test_scores_mean, label="Cross-validation score",
                 color="navy", lw=lw)
    plt.fill_between(param_range, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.2,
                     color="navy", lw=lw)
    plt.legend(loc="best")
    return plt, title, param_name, train_scores, test_scores, None, None
```

### 4.1.3 正規化表現評估

另一種診斷模型性能的方法是利用正規化表現評估。正規化方法的目的是確保模型不會過於複雜，通過減少特徵權重的大小來實現這一點，進而提高模型的泛化能力。一般來說，模型越過擬合，正規化的影響越小，因為權重已經被降低到接近零的程度。

```python
from sklearn.linear_model import Ridge
from sklearn.model_selection import cross_val_score

def plot_regularization_performance(X_train, y_train, X_test, y_test):
    # 1.使用不同程度的正則化，繪製 Rige regression 模型的 cross validation score 曲綫 
    alphas = np.logspace(-10, 2, 10)
    scores = []
    for alpha in alphas:
        rg = Ridge(alpha=alpha)
        scores.append(cross_val_score(rg, X_train, y_train, cv=5))
    scores = np.array(scores)
    mean_scores = np.mean(scores, axis=1)
    std_scores = np.std(scores, axis=1)
    plt.plot(alphas, mean_scores, label="Cross Validation Score")
    plt.fill_between(alphas, mean_scores - std_scores, mean_scores + std_scores, alpha=0.1)

    # 2.用測試集評估最好的 alpha 的性能 
    best_alpha = alphas[np.argmax(mean_scores)]
    rg = Ridge(alpha=best_alpha)
    test_score = rg.fit(X_train, y_train).score(X_test, y_test)
    plt.scatter(best_alpha, test_score, label="Test Score", marker='o')
    
    plt.legend(loc="best")
    plt.xlabel("alpha")
    plt.ylabel("Score")
    plt.xscale("log")
    return plt, best_alpha
```

上面三種方法可以幫助您找到能夠通過學習訓練數據建立出較為泛化的模型的最佳超參數。當您需要訓練一個具有高泛化能力的模型時，這些方法是非常有用的。