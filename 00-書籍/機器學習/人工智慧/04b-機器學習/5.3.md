## 5.3 ROC曲線

## 什麼是ROC曲線?

ROC (Receiver Operating Characteristic) 曲線是用於評估二元分類器 (binary classifier) 表現優劣的一種方法。它是以檢測錯誤率 (false positive rate，FPR) 為 x 軸，以真實正例率 (true positive rate，TPR) 為 y 軸，將模型在不同閥值之下的 FPR-TPR 做圖，從而繪制出的一條曲線。

## 什麼是真實正例率?

TPR 指真實正例率，又稱召回率 (recall)，計算公式為 $TPR=\frac{TP}{TP+FN}$。其中 TP (True Positive), FN (False Negative) 分別為真實值為正例且預測為正例的樣本數量和真實值為正例但預測為負例的樣本數量。

## 什麼是檢測錯誤率?

FPR 指檢測錯誤率 (false positive rate)，計算公式為 $FPR=\frac{FP}{FP+TN}$。其中 FP (False Positive), TN (True Negative) 分別為真實值為負例但預測為正例的樣本數量和真實值為負例且預測為負例的樣本數量。

## 如何繪製 ROC 曲線?

使用 Scikit-Learn 庫中的 roc_curve() 函數計算在不同閾值下的 FPR 和 TPR。需要牢記的是，ROC 曲線越靠近左上角，代表該模型越準確。

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# 假設 y_test 為測試集的實際標籤值，y_score 為預測正例的機率值，例如KNN分類器的k=5時
fpr, tpr, thresholds = roc_curve(y_test, y_score)

# 繪製ROC曲線
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve')
plt.show()
```

## 如何評估 ROC 曲線的效能？

ROC 曲線是評估二元分類器表現的常用指標之一，除了繪製 ROC 曲線之外，還可以用 AUC（Area Under Curve，曲線下面積）來評估模型的分類效能。當 AUC 越靠近 1，代表該模型的分類效能越優秀。相對地，當 AUC 越靠近 0.5，代表該模型的效果越差，甚至比隨機猜測還要差。

```python
AUC_score = roc_auc_score(y_test, y_score)
print('AUC score:', AUC_score)
```

此外，我們還可以將不同模型的 ROC 曲線繪製在同一張圖上，用來進行比較。

```python
# 假設 y_score_1 和 y_score_2 分別來自於兩個不同分類器的預測正例的機率值
fpr_1, tpr_1, thresholds_1 = roc_curve(y_test, y_score_1)
fpr_2, tpr_2, thresholds_2 = roc_curve(y_test, y_score_2)

# 繪製 ROC 曲線
plt.plot(fpr_1, tpr_1, label='Classifier 1')
plt.plot(fpr_2, tpr_2, label='Classifier 2')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve comparison')
plt.legend()
plt.show()
```