## 5.1 交叉驗證

在機器學習任務中，模型的泛化能力是其核心問題之一。為了確保模型在未見過的數據中有良好的表現，我們需要用一部分數據來測試其泛化能力。在實際應用中，我們很難擁有足夠多的數據來訓練和測試，因此需要盡可能有效地利用現有數據。一種常用的方法是交叉驗證（Cross Validation）。

### 5.1.1 K 折交叉驗證

K 折交叉驗證是交叉驗證的一種常用形式，其基本思想是將數據集分成 K 個互不重疊的子集，然後對於每一個子集，用其它 K-1 個子集的數據來訓練模型，再用這個子集來測試模型，最後將 K 次測試結果的平均值作為模型的性能指標。例如，若 K=5，則可將數據集分為 5 個子集，每次用 4 個子集來訓練模型，用另一個子集測試模型，進行 5 次交叉驗證以獲取穩定可靠的性能指標。

在 scikit-learn 中，可以使用 `KFold` 類來實現 K 折交叉驗證，其主要參數有：

- n_splits：K 的值，即交叉驗證次數。
- shuffle：是否在分割前將數據隨機排序。
- random_state：隨機種子，確保每次實驗結果一致。

舉例而言，我們可以使用 `KNeighborsClassifier` 類對鳶尾花數據集進行 5 折交叉驗證，代碼如下所示：

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import KFold
from sklearn.neighbors import KNeighborsClassifier

# 加載鳶尾花數據集
iris = load_iris()
X, y = iris.data, iris.target

# 定義 K 折交叉驗證
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# 定義 K 最近鄰分類器
knn = KNeighborsClassifier(n_neighbors=3)

# 進行 K 折交叉驗證
scores = []
for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    knn.fit(X_train, y_train)
    score = knn.score(X_test, y_test)
    scores.append(score)

print("Accuracy: %0.4f" % (sum(scores)/len(scores)))
```

執行上述代碼，可以得到以下結果：

```
Accuracy: 0.9667
```

由於隨機種子設置為 42，因此每次實驗結果均一致。可以看到，我們的 K 最近鄰分類器在鳶尾花數據集上的總體準確率為 0.9667。

### 5.1.2 Stratified K 折交叉驗證

在進行分類任務時，為了保證數據的平衡性，我們通常會使用層次貝意抽樣（Stratified Sampling）技術，即在每個子集中，每個類別的數量都要大致相等。在交叉驗證中，我們也可以使用 Stratified K 折交叉驗證，保證每個子集中每個類別的數量都大致相等。

在 scikit-learn 中，可以使用 `StratifiedKFold` 類來實現 Stratified K 折交叉驗證，其主要參數與 `KFold` 類相同。舉例而言，我們可以使用 `SVC` 類對鳶尾花數據集進行 10 折交叉驗證，代碼如下所示：

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import StratifiedKFold
from sklearn.svm import SVC

# 加載鳶尾花數據集
iris = load_iris()
X, y = iris.data, iris.target

# 定義 Stratified K 折交叉驗證
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# 定義支持向量分類器
svc = SVC(kernel="linear", C=1)

# 進行 Stratified K 折交叉驗證
scores = []
for train_index, test_index in skf.split(X, y):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    svc.fit(X_train, y_train)
    score = svc.score(X_test, y_test)
    scores.append(score)

print("Accuracy: %0.4f" % (sum(scores)/len(scores)))
```

執行上述代碼，可以得到以下結果：

```
Accuracy: 0.9800
```

可以看到，我們的支持向量分類器在鳶尾花數據集上的總體準確率為 0.9800。与 K 折交叉驗證相比，Stratified K 折交叉驗證通常能夠更好地保證數據的平衡性。