## 3.5 主成分分析

主成分分析（Principal Component Analysis，PCA）是一種經典的降維技術，可以將高維數據轉換成低維數據，從而將複雜的數據結構簡化為較為簡單的結構。在機器學習中，PCA 常用於數據壓縮、特徵提取等場景，是一個非常常用的方法。

PCA 的目的是找到一個投影矩陣，將原始的高維數據映射到低維空間中，而同時保留盡量多的數據變異性。這個疊加特徵矩陣的過程成為主成分分析，通常使用奇異值分解（Singular Value Decomposition，SVD）來實現。如果數據維度特別高，那麼PCA就可以消除數據裡的相關性和噪聲，從而形成新的相互獨立的變量，進而方便進行分析和建模，增強模型的泛化性能。下面是一個示例：


```python
from sklearn.decomposition import PCA
from sklearn.datasets import load_iris

import matplotlib.pyplot as plt
import numpy as np

# 載入數據集
iris = load_iris()
# 取出特徵和標籤
X = iris.data
y = iris.target
# 創建PCA實例
pca = PCA(n_components=2, whiten=True)
# 擬合數據集
pca.fit(X)
# 提取主成分
X_pca = pca.transform(X)

# 畫圖展示原始數據和降維後的數據
fig, axes = plt.subplots(1, 2, figsize=(10, 5))

axes[0].scatter(X[:, 0], X[:, 1], c=y, alpha=0.8)
axes[0].set_xlabel('Sepal length')
axes[0].set_ylabel('Sepal width')
axes[0].set_title('Original Data')

axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=y, alpha=0.8)
axes[1].set_xlabel('Principal Component 1')
axes[1].set_ylabel('Principal Component 2')
axes[1].set_title('Reduced Dimension Data')

plt.show()
```

在這個例子中，我們使用 scikit-learn 的 PCA 函數來實現主成分分析，將鳶尾花數據集轉換為二維數據。使用`.fit()`函數，我們擬合了原始鳶尾花數據集，提取了前兩個主成分，並使用`.tranform()`函數轉換了原始數據集。這樣，就可以把原始的 4 維數據降維成 2 維，同時保留了大部分數據的變異性。

在圖像顯示的原始數據和降維後的數據，可以明顯看出，降維後的數據可以很好地區分不同品種的鳶尾花，而且不同品種之間的差異也更加明顯。

當然，PCA 的使用不僅僅限於數據可視化，PCA 還可以應用於特徵選擇、數據去噪、模型加速等方面，並且還可以結合其他學習算法進行更高效的特徵學習。如果感興趣，建議多做一些練習，加強對 PCA 的理解。