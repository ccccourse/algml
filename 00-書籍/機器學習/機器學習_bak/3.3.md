## 3.3 層次聚類

層次聚類（Hierarchical Clustering）是一種比較特殊的聚類難度，因為該演算法基於對距離或相似度的度量，它不會將數據點分配為預先設定的 K 群，而是形成一個嵌套的包含集合的層次（如同樹狀模型），該模型不需要預先指定聚類數，且具有可視化輸出的優點，因此深受許多領域的學者和應用者的喜愛。

### 總體概述

層次聚類可以分為以下兩類：

- 凝聚型層次聚類：每次將最靠近的兩個點合併成同一簇，直到所有點都是同一簇為止。
- 分裂型層次聚類：將一開始的所有點劃分為一簇，然後每次將該簇中的一部分劃分出來，直到每個簇只有一個點為止。

其中，凝聚型層次聚類是最常用和最優秀且效果最佳的算法，在本篇文章中我們將說明凝聚型層次聚類算法。

### 凝聚型層次聚類

scikit-Learn 採用 Agglomerative(Clustering) 類實現了一組凝聚型層次聚類算法。屬於agglomerative clustering演算法的主要概念是 :從"下而上"生成層次，創建群集層次，將相似的項目一起放在相同的群集中。

其基本思想是，首先把每個數據點當作一個簇，然後不斷的將距離最近的兩個簇合併成一個新的簇，直到所有數據點都在同一個簇內為止。合併的方式可以是「最小距離」、「最大距離」或「平均距離」等方式進行合併。

scikit-Learn 中的 AgglomerativeClustering 類可以通過以下參數調整聚類的效果：

- n_clusters : 聚類的簇數，可以預先指定
- affinity : 聚類時使用的距離度量方式，可以是「euclidean」、「l1」、「l2」、「manhattan」、「cosine」等方式。
- linkage : 聚類時採用的合併方式，可以是「ward」、「complete」、「average」、「single」等方式。

下面通過一個例子來說明層次聚類的實現方法

### 程式範例

```python
from sklearn.cluster import AgglomerativeClustering
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt

#創建虛擬資料
X,y_true=make_blobs(n_samples=300,centers=4,cluster_std=0.60,random_state=0)

#像素設置
plt.rcParams['figure.figsize']=(16,9)

#畫散點圖
plt.scatter(X[:,0],X[:,1],s=50,alpha=0.7)

#使用層次聚類演算法
model=AgglomerativeClustering(n_clusters=4)

#拟合模型
model.fit(X)

#數據預測
y_kpre=model.fit_predict(X)

#繪畫圖形
plt.scatter(X[:,0],X[:,1],c=y_kpre,s=50,alpha=0.7)
plt.grid(True)
plt.title("AgglomerativeClustering")
plt.xlabel("Number of features")
plt.ylabel("Data value")
plt.show()
```

首先，我們使用make_blobs生成4個聚類，每個聚類中有300個資料點。在這個例子中，我們指定了常數和隨機狀態使得每次運行程式結果都一樣。接著，我們繪製出未聚類的資料點。作為比較我們帶入了一個層次聚類演算法，使用它預測模型並繪製出可視化的散點圖，這樣可以視覺化比較兩者之間的差異。

### 結語

層次聚類，在某些場景下尤其是在較為簡單的數據分佈情況下，能夠極大的提升聚類的精度。擁有良好的可視化效果，方便使用人員理解分析，不必預先指定聚類簇數這一優點使層次聚類越來越受到應用領域的青睞，這也是我們需要學習和掌握這一演算法的原因。