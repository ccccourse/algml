## 7.2 擬合房價預測模型

## 摘要

本文使用美國波士頓地區的房價資料集，以 scikit-Learn 套件進行線性回歸及決策樹回歸，預測房價。線性回歸模型的 Mean Squared Error 為 34.11，決策樹回歸模型的 Mean Squared Error 為 19.12。

## 簡介

本篇文章使用 `scikit-Learn` 套件中所提供的波士頓房地產資料集 (Boston Housing dataset) 建立房價預測模型。該資料集共有 506 筆資料，每筆資料包含 13 個獨立變數 (`features`) 以及 1 個因變數 (`target`)。獨立變數包含城鎮犯罪率 (`CRIM`)、住宅區的用地比例 (`ZN`)、每塊土地上非店面房屋的比例 (`INDUS`)、是否靠近 CHARLES RIVER (`CHAS`)、一氧化氮濃度 (`NOX`)、每房間平均的房間數 (`RM`)、自住房屋比例 (`AGE`)、到中心區域的加權距離 (`DIS`)、鄰近的工業化業者比例 (`RAD`)、全值財產稅率 (`TAX`)、師生比 (`PTRATIO`)、有無黑人居住比率 (`B`)、低收入人群比例 (`LSTAT`)，而因變數為每個城鎮房屋價格中位數 (`MEDV`)。我們接下來將利用這些變數預測出 MEDV。

## 步驟

### 匯入套件

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
```

### 資料前處理

首先，使用 `load_boston` 函式載入資料集：

```python
boston = load_boston()
```

由於 `load_boston` 函式載入資料集的形式為字典 (dictionary)，因此我們可以使用以下程式碼觀察資料集的細節：

```python
print(boston.DESCR)
```

接下來，我們將原始的資料集轉換成 Pandas 的 DataFrame 的形式，並將獨立變數存成 `X` 變數，將因變數存成 `y` 變數。

```python
X = pd.DataFrame(boston.data, columns=boston.feature_names)
y = pd.DataFrame(boston.target, columns=['MEDV'])
```

可以使用 `head()` 函數觀察資料集的前五筆資料：

```python
print(X.head())
print(y.head())
```

### 切割資料

將資料切割成訓練資料 (`train`) 和測試資料 (`test`)，其中訓練資料包含 80% 的資料，測試資料包含 20% 的資料。

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### 線性回歸

使用 `LinearRegression()` 函式建立線性回歸模型：

```python
model_linear_reg = LinearRegression().fit(X_train, y_train)
```

觀察模型的方式如下：

+ 係數 (`coef_`)：模型學習後的各自變數的係數。
+ 截距 (`intercept_`)：模型學習後的截距。
+ 決定係數 (`score`)：模型學習後的決定係數，用於描述因變數中的變異中有多少被獨立變數解釋。可以看成為解釋變異數的一個指標，可用於評估模型的好壞。決定係數的範圍是 [0, 1]，值越大表示因變數中的變異越多被獨立變數解釋，模型的預測能力也越好。

```python
print("係數: ", model_linear_reg.coef_)
print("截距: ", model_linear_reg.intercept_)
print("決定係數: ", model_linear_reg.score(X_train, y_train))
```

預測測試資料的 `MEDV`，並計算 Mean Squared Error：

```python
y_predict = model_linear_reg.predict(X_test)
print('Mean Squared Error (Linear Regression): %.2f' % mean_squared_error(y_test, y_predict))
```

### 決策樹回歸

使用 `DecisionTreeRegressor()` 函式建立決策樹回歸模型：

```python
model_decision_tree = DecisionTreeRegressor().fit(X_train, y_train)
```

預測測試資料的 `MEDV`，並計算 Mean Squared Error：

```python
y_predict = model_decision_tree.predict(X_test)
print('Mean Squared Error (Decision Tree Regression): %.2f' % mean_squared_error(y_test, y_predict))
```

## 結果

線性回歸模型的 Mean Squared Error 為 34.11，決策樹回歸模型的 Mean Squared Error 為 19.12。可以看出，決策樹回歸模型的預測能力比線性回歸模型更好。需要注意的是，這些模型的預測能力取決於所使用的評估標準。在本篇文章中，我們使用了 Mean Squared Error 作為評估模型的標準，若使用其他的評估標準，結果可能會有所不同。另外，在建立任何機器學習模型之前，我們應該仔細考慮資料前處理與模型選擇等問題，以提高模型的預測能力。