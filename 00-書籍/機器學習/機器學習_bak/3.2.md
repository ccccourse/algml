## 3.2 K-Means

K-Means 是 Clustering 中相當普及的方法，用於將資料分為 K 個 cluster。K-Means 的核心思想是根據相似性將資料點分為不同的 cluster，當其中一個點被劃分入某一 cluster 後，其它的點也會按照相似性被劃分到同一個 cluster 中。K-Means 的流程如下：

1. 隨機從資料集中選擇 K 個點作為初始中心
2. 將所有點分配到最近的中心點所在的 cluster 中
3. 將每個 cluster 的中心點更新為所有點的平均值
4. 重複步驟 2 ~ 3 直到中心點不再變化，或達到最大迭代次數

K-Means 與其他 clustering 方法相比的優勢在於其運算速度快、易於實現、對於大規模資料具有良好的可擴展性。

下面我們看一個 scikit-learn 中的 K-Means 範例，用於分類手寫數字：

``` python

# 匯入需要的庫
import numpy as np
from sklearn.datasets import load_digits
from sklearn.cluster import KMeans
from sklearn.metrics import homogeneity_score

# 載入手寫數字數據集
digits = load_digits()
data = digits.data

# 設定參數，n_clusters 為 K 值，init 為初始中心點的選擇方式
estimator = KMeans(n_clusters=10, init='k-means++')

# 訓練模型
estimator.fit(data)

# 評估模型的性能
labels = estimator.labels_
score = homogeneity_score(digits.target, labels)

print("K-Means 模型的性能: ", score)
```

此範例中，我們先載入手寫數字數據集，並使用 KMeans 對其進行 clustering。其中，參數 n_clusters 為 K 值，即我們要將數據集分為幾個 cluster。init 為初始中心點的選擇方式，'k-means++' 表示使用 KMeans++ 算法選擇初始中心點。`homogeneity_score` 用於評估 clustering 的性能，該函數返回 cluster 源自同一類別的比率。最後計算出分類的性能得分。

這裡也提供 `MiniBatchKMeans` 的使用方法，`MiniBatchKMeans` 是 KMeans 的一種變種，原理基本相同，不同的是它只使用了一部分的樣本來更新中心點。這使得 `MiniBatchKMeans` 的速度比 KMeans 更快，但也會帶來一些精度上的損失。

``` python

# 匯入需要的庫
from sklearn.cluster import MiniBatchKMeans

# 設定參數，n_clusters 為 K 值，init 為初始中心點的選擇方式
estimator = MiniBatchKMeans(n_clusters=10, init='k-means++')

# 訓練模型
estimator.fit(data)

# 評估模型的性能
labels = estimator.labels_
score = homogeneity_score(digits.target, labels)

print("MiniBatchKMeans 模型的性能: ", score)
```

利用 `MiniBatchKMeans` 訓練模型的過程與 `KMeans` 類似。`MiniBatchKMeans` 的參數設置基本與 KMeans 相同。

由於 `MiniBatchKMeans` 較 KMeans 更快，如果忽略一定程度的精度損失，常常在大規模資料集上處理 clustering 任務。