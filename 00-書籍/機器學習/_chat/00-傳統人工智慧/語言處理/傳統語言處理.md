## ccc: 不用神經網路，傳統方法如何做語言處理

ChatGPT: https://chatgpt.com/c/67661ed0-e3f0-8012-abde-1c148cb472a0

傳統的自然語言處理（Natural Language Processing, NLP）方法主要基於規則、統計、結構化知識和符號邏輯等技術，以下是傳統方法處理語言的主要框架和實現方式：

---

## **1. 預處理技術**
這是 NLP 任務的第一步，目的是將原始文本轉換為結構化數據，方便後續處理。

### **(1) 分詞（Tokenization）**
- **目標**：將句子劃分為詞或短語單元。
- **方法**：
  - 基於規則：
    - 使用空格分隔（適合英文）。
    - 基於詞典匹配（適合中文）。
  - 統計方法：
    - 最大匹配算法（Forward/Backward Maximum Matching）。
    - 雙向最大匹配（BiMM）。

### **(2) 停用詞過濾（Stop Words Removal）**
- **目標**：去除對語義貢獻較小的詞（如 "的"、"is"、"and" 等）。
- **方法**：
  - 建立停用詞表，匹配並過濾。

### **(3) 詞形還原（Lemmatization）與詞幹提取（Stemming）**
- **目標**：將詞歸一化。
  - 詞形還原：將動詞還原到原形（如 "running" → "run"）。
  - 詞幹提取：刪去詞的後綴（如 "cats" → "cat"）。
- **方法**：
  - 基於規則的詞幹提取器（如 Porter Stemmer、Lancaster Stemmer）。
  - 詞性標註後的規則還原。

### **(4) 詞性標註（Part-of-Speech Tagging, POS）**
- **目標**：為每個詞分配一個詞性（如名詞、動詞）。
- **方法**：
  - 基於規則：構建詞性轉移規則（如 "a/an" 通常後接名詞）。
  - 統計方法：使用隱馬爾可夫模型（HMM）進行詞性標註。

---

## **2. 基於統計的方法**
統計方法利用語料庫中詞的頻率和分佈特性，處理語言的語義和語法。

### **(1) N-gram 語言模型**
- **核心思想**：
  計算詞序列出現的概率，假設序列中的詞僅依賴於前 \( n-1 \) 個詞。
  \[
  P(w_1, w_2, ..., w_n) \approx P(w_1)P(w_2|w_1)...P(w_n|w_{n-1})
  \]

- **應用**：
  - 拼音輸入法：根據上下文選擇正確的詞。
  - 句子生成：基於概率選擇最可能的後續詞。

### **(2) 詞頻統計與詞共現分析**
- **詞頻統計（TF）**：
  - 計算詞在文檔中的頻率。
- **詞共現分析（Co-occurrence Analysis）**：
  - 基於詞之間同時出現的頻率構建關聯圖，提取關鍵詞或詞組。

### **(3) TF-IDF**
- **核心思想**：
  衡量詞對文檔的重要性，通過詞頻（TF）和反文檔頻率（IDF）計算：
  \[
  \text{TF-IDF} = \text{TF} \times \text{IDF}, \quad \text{IDF} = \log\frac{N}{1 + n_t}
  \]
  - \( N \)：文檔總數。
  - \( n_t \)：包含詞 \( t \) 的文檔數。

- **應用**：
  - 關鍵詞提取
  - 信息檢索（IR）

---

## **3. 基於規則的方法**
這些方法使用人工定義的語法、規則和邏輯進行語言處理。

### **(1) 正則表達式**
- **目標**：匹配文本中的特定模式。
- **應用**：
  - 提取電子郵件地址：
    ```
    正則：[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+
    ```
  - 日期識別、電話號碼提取。

### **(2) 上下文無關文法（CFG）**
- **目標**：基於語法規則解析句子結構。
- **例子**：
  ```
  S → NP VP
  NP → Det N
  VP → V NP
  ```

- **應用**：
  - 自然語言解析（Parsing）
  - 語法檢查

---

## **4. 主題建模**
主題建模通過提取文本中的潛在主題，理解文檔語義。

### **(1) 潛在語義分析（LSA）**
- **核心思想**：
  使用奇異值分解（SVD）降維，從詞-文檔矩陣中提取語義空間。

### **(2) 潛在狄利克雷分佈（LDA）**
- **核心思想**：
  假設文本由若干潛在主題組成，主題由詞的概率分佈表示。

- **應用**：
  - 文檔聚類
  - 信息檢索

---

## **5. 符號邏輯與知識表示**
符號邏輯方法依賴於嚴格的邏輯推理，用於語言的精確理解。

### **(1) 一階邏輯（FOL）**
- **核心思想**：
  使用邏輯表示句子，進行推理和檢索。

- **例子**：
  - 表示：「所有人都會死。」
    \[
    \forall x (\text{人}(x) \rightarrow \text{會死}(x))
    \]

### **(2) 知識庫系統**
- **目標**：
  利用結構化的知識圖譜處理語言。
- **應用**：
  - 問答系統（如基於 DBpedia 的問答）。

---

## **6. 信息檢索與匹配**
通過文本的相似性度量，進行信息檢索和排序。

### **(1) 向量空間模型（VSM）**
- **核心思想**：
  將文本表示為詞向量，通過餘弦相似度計算文本相似性：
  \[
  \text{Cosine Similarity} = \frac{\vec{A} \cdot \vec{B}}{\|\vec{A}\| \|\vec{B}\|}
  \]

### **(2) 編碼與相似性匹配**
- **應用**：
  - 使用 TF-IDF 或詞袋模型（BoW）表示文檔，再進行匹配。

---

## **7. 傳統 NLP 方法的應用案例**

| 方法                       | 應用場景                                   |
|--------------------------|----------------------------------------|
| 正則表達式                 | 信息抽取（如日期、郵箱提取）                  |
| N-gram 模型               | 拼音輸入法、機器翻譯、語言生成                  |
| TF-IDF                   | 文檔檢索、文本分類                            |
| CFG                     | 語法檢查、語義解析                            |
| 主題建模（LSA/LDA）       | 文件分類、主題發現                            |
| 知識庫推理                 | 問答系統、專家系統                            |

---

雖然這些方法在某些特定領域仍然有效，但它們的主要局限在於難以處理長距離依賴、模糊語義和大量非結構化數據。這些挑戰促使神經網路和深度學習在 NLP 領域的快速發展。然而，傳統方法在處理規模較小且結構化的問題時仍具有競爭力。